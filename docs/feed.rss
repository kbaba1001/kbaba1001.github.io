<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" version="2.0">
  <channel>
    <title>ハッカーと漫画家</title>
    <link>https://www.kbaba1001.com/</link>
    <atom:link href="https://www.kbaba1001.com/feed.rss" rel="self" type="application/rss+xml"/>
    <description>Clojure 好きなプログラマ kbaba1001 のブログ</description>
    <lastBuildDate>Sun, 17 Dec 2023 15:00:00 GMT</lastBuildDate>
    <language>ja_JP</language>
    <generator>Lume v2.0.1</generator>
    <item>
      <title>君は4つのMacbookAirを手に入れた</title>
      <link>https://www.kbaba1001.com/posts/202503191106_4-macbook-air/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202503191106_4-macbook-air/</guid>
      <content:encoded>
        <![CDATA[<h2>ジャンクマシン</h2>
        <p>ジャンク品の Macbook Air を知人とかメルカリとかから１台１万円くらいで譲り受けた。
        なんと４台もある。</p>
        <p>実は古い Macbook は非公式の互換バッテリーが Amazon で 5,000 ～ 7,000円くらいで売っているので
        自力で交換することにした。</p>
        <p>ジャンク品だと電源ケーブルもなかったり、あっても使い古されたりしているので
        Amazonで互換品を買うことにした。</p>
        <p>そうすると、予算感としては１台あたり、</p>
        <ul>
        <li>本体: 10,000円</li>
        <li>バッテリー: 6,000円</li>
        <li>電源: 4,000円</li>
        </ul>
        <p>で、約2万円。</p>
        <p>これでそこそこの性能のマシンが手に入るなら安いか。</p>
        <h2>どう使うか</h2>
        <p>Macbook Air には Linux を入れてサーバー or ちょっとした持ち運びマシンにする予定。</p>
        <p>今使っているノートパソコンはゲーミングPCなので、重量が重いし電池のもちが悪い…。
        悪いマシンではないのだが持ち歩くには辛いのだった。</p>
        <p>そこで MacbookAir を Linux 化して SSH やリモートデスクトップでアクセスできるようにしておけば便利かなと思った。</p>
        <p>あるいは Kubernetes クラスタを作ってもいい。</p>
        <h2>Gentoo Linux を入れる</h2>
        <p>妻がOSを学びたいというので、それなら <a href="https://www.gentoo.org/">Gentoo Linux</a> から始めようという話になった。</p>
        <p>自分も Gentoo Linux を使うのは久々なので一緒にやってみる予定。</p>
        ]]>
      </content:encoded>
      <pubDate>Wed, 19 Mar 2025 11:06:39 GMT</pubDate>
    </item>
    <item>
      <title>水彩画修行</title>
      <link>https://www.kbaba1001.com/posts/202502281007_water-color-drawing/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202502281007_water-color-drawing/</guid>
      <content:encoded>
        <![CDATA[<p>ほぼ毎日のように水彩画を描いている。</p>
        <h3>夜景</h3>
        <p><img src="https://www.kbaba1001.com/img/posts/202502281007/image_1.jpg" alt="image_1.jpg"></p>
        <p>ぱくたその写真を元に書いた絵。夜の景色のキラキラした感じを描きたかった。</p>
        <h3>日本庭園</h3>
        <p><img src="https://www.kbaba1001.com/img/posts/202502281007/image_2.jpg" alt="image_2.jpg"></p>
        <p>らくがき。草の描き方に課題を感じ始めた。</p>
        <h3>温泉と美女</h3>
        <p><img src="https://www.kbaba1001.com/img/posts/202502281007/image_3.jpg" alt="image_3.jpg"></p>
        <p>これもぱくたその写真から。</p>
        <p>松より手前の水面を詳細に描くべきだったとか色々反省があるけど、
        人物はきれいに書けて満足している。</p>
        <h3>森の少女</h3>
        <p><img src="https://www.kbaba1001.com/img/posts/202502281007/image_4.jpg" alt="image_4.jpg"></p>
        <p>「背景を雑に、前景を丁寧に」がテーマになってきているが、
        この絵を書いたとき胃腸炎でとても体調が悪くて細かいところをうまくかけていない。</p>
        <p>しかしなんとなく成功に向かっている感じはある。</p>
        <h3>りんごとバナナ</h3>
        <p><img src="https://www.kbaba1001.com/img/posts/202502281007/image_5.jpg" alt="image_5.jpg"></p>
        <p>カラーデッサン。</p>
        <h3>似顔絵</h3>
        <p><img src="https://www.kbaba1001.com/img/posts/202502281007/image_6.jpg" alt="image_6.jpg">
        <img src="https://www.kbaba1001.com/img/posts/202502281007/image_7.jpg" alt="image_7.jpg"></p>
        <p>誰の絵っていうのはあえて書かないけど、有名人の似顔絵。
        もちろん非公式のファンアート。</p>
        <p>だいぶ水彩で色を置く感覚に慣れてきたところ。</p>
        <h3>オオハシ</h3>
        <p><img src="https://www.kbaba1001.com/img/posts/202502281007/image_8.jpg" alt="image_8.jpg"></p>
        <p>南国をイメージして描いたオオハシ。
        鳥は丁寧に、背景の木々はやや雑に描くというのがうまくできた気がする。</p>
        <p>こういうタッチや明暗の強弱をつけるのをもっとやりたい。</p>
        <h3>ギターを引く女性</h3>
        <p><img src="https://www.kbaba1001.com/img/posts/202502281007/image_9.jpg" alt="image_9.jpg"></p>
        <p>またしてもぱくたそベースの絵。
        ギター＋女性＋イラストというとどうしても僕の中では江口寿史さんが思い浮かぶので、
        線画をしっかりとペンで書いてからややフラットな感じで着色した。
        ギターとかバイクとかはフリーハンドでもそれなりに描けるようになってきた。</p>
        <h2>動画活動</h2>
        <ul>
        <li><a href="https://youtube.com/shorts/zdIm2FfrOMM?feature=share">ショート動画１</a></li>
        <li><a href="https://youtube.com/shorts/RS-PluvWlJ0?feature=share">ショート動画２</a></li>
        </ul>
        <p>X や Instagram を再開する気にもなれないので YouTube でお絵かき動画を配信することにした。
        まずはショートで知名度を稼ぎたい。</p>
        <h2>紙について</h2>
        <p>F6のコットマンを使っていたが、どうもコットマンの若干水をハネる感じが好きになれず、
        ホワイトワトソンに切り替えた。
        大きさも F6 から F4 にしてやや小さくした。
        「絵がうまくなりたかったら大きい紙に描くように」と昔デッサン教室で言われたことが呪いになっていて、
        あまり小さい紙に描くのが好きではないのだが、F4は結構気楽に書けて良い。
        もともとはカバンに入れて持ち運ぶように買ったのだが、家でも結構使っている。</p>
        <p>しかしやはりある程度ちゃんと描こうとしたらF6くらいの大きさは最低限欲しい感じがする。
        ましてや飾る前提の絵ならもっと大きいほうが…。
        となるとなかなか机の大きさとか保管場所とかに困るのであった。</p>
        ]]>
      </content:encoded>
      <pubDate>Fri, 28 Feb 2025 10:07:42 GMT</pubDate>
    </item>
    <item>
      <title>透明水彩の練習</title>
      <link>https://www.kbaba1001.com/posts/202501300821_practice-of-water-color-painting/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202501300821_practice-of-water-color-painting/</guid>
      <content:encoded>
        <![CDATA[<h2>透明水彩によるカラーデッサン</h2>
        <p><img src="https://www.kbaba1001.com/img/posts/202501300821/color1.jpg" alt="color1"></p>
        <p><img src="https://www.kbaba1001.com/img/posts/202501300821/color2.jpg" alt="color2"></p>
        <p>こんな感じで透明水彩を練習中。
        濃い色を出すのが思ったより難しいが、慣れてきた。
        ただ、自分の性格上パキッとした絵を描きたいので、
        不透明水彩のほうが向いている気がする。</p>
        <p>水彩紙も手持ちのものがすべて細目だったので、中目くらいのやつを買っておきたい。</p>
        <h2>モノクロデッサン</h2>
        <p><img src="https://www.kbaba1001.com/img/posts/202501300821/monochrome.jpg" alt="monochrome"></p>
        <p>鉛筆デッサンも相変わらずやっている。</p>
        ]]>
      </content:encoded>
      <pubDate>Thu, 30 Jan 2025 08:21:32 GMT</pubDate>
    </item>
    <item>
      <title>日常にあるものでデッサンをする</title>
      <link>https://www.kbaba1001.com/posts/202501200854_sketching-commodities/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202501200854_sketching-commodities/</guid>
      <content:encoded>
        <![CDATA[<h2>日用品のデッサン</h2>
        <p><img src="https://www.kbaba1001.com/img/posts/202501200854/sketching.jpg" alt="日常スケッチ"></p>
        <p>デッサンの入門書を見ると石膏の三角錐などがサンプルに出てくることもあるが、
        そんなの家にないので日常的に目にするものをデッサンするのが
        いいと思っている。</p>
        <p>例えば、カフェの机の上。</p>
        <p>マグカップ、透明なコップ、おしぼり。この３つでも質感の違いを意識して
        デッサンの練習ができる。</p>
        <p>ちょっとしたポットや電球などの工業製品も練習に向いているし、
        空き缶やペットボトルを描いてみるだけでもいい。</p>
        <p>今年も絵をたくさん描きたいので、こういうウォーミングアップを大切にしたいと思う。</p>
        <h2>ヌードデッサン会に行ってきた</h2>
        <p><img src="https://www.kbaba1001.com/img/posts/202501200854/pose01.jpg" alt="ポーズ1">
        <img src="https://www.kbaba1001.com/img/posts/202501200854/pose02.jpg" alt="ポーズ2"></p>
        <p>町中のヌードデッサン会が単発参加できたので行ってきた。
        こういうイベントが多いのは都会という感じがする。正直助かる。</p>
        <p>今まで人物はだいぶ描いてきたが、やはり短い時間で描くのはやはり難しい。</p>
        <p>最近の考えとしては、その人物の雰囲気やポーズをどう捉えるかが案外重要だなと思っている。
        例えば１枚目の寝ているポーズは、背中から足にかけてのゆったりとした曲線美を意識していて、
        最初にそれを下書きしたあと人物として描くようにした。
        ある程度人体のパーツの大きさや描き方などを覚えたら、
        このような概念を意識してみると描きやすくなる気がする。</p>
        <p>参加したデッサン会は意外と初心者が多くてベテランは少なかった。
        自分もすっかりベテラン側かなと思うが、どちらかと言うと自分が一番下手なくらいの回に参加するほうが学びがあって面白い。
        こういう町中のデッサン会に以前参加したのはもう１０年以上前なので、
        その頃は周りの画力に驚いたものだがやはり自分の画力も上がっているし、
        当時ほどの驚きというか新鮮さはなかった。</p>
        <p>なんかもう、そもそも持ってきている道具を見るだけでもある程度その人の画力がわかるようになってしまった。
        昔わからなかったことが色々とわかるようになっているのを認識した。</p>
        ]]>
      </content:encoded>
      <pubDate>Mon, 20 Jan 2025 08:54:40 GMT</pubDate>
    </item>
    <item>
      <title>2025年 新年</title>
      <link>https://www.kbaba1001.com/posts/202501071500_new-year-2025/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202501071500_new-year-2025/</guid>
      <content:encoded>
        <![CDATA[<p>新年あけましておめでとうございます。
        今年も当ブログをよろしくお願い致します。</p>
        <h3>引っ越し</h3>
        <p>私事ですが、2024年末に引っ越しをしました。
        静岡から東京に戻った形となります。
        コロナも落ち着いてオフラインイベントも増えてきたことで
        何かと東京の用事も増えてきましたし、
        一方静岡の家では路線バスが大幅に減って生活の不便が増えてきており、
        夫婦で話し合った結果、東京に引っ越そうということになりました。</p>
        <h3>個人開発</h3>
        <p>去年から作っている個人開発システムがいくつかあり、
        引っ越しなどでバタバタしていた関係でどれも中途半端な状態となっているので、
        折を見て再開したいなという気持ちです。</p>
        <p>具体的には次は終わらせたいところ</p>
        <ul>
        <li>ローカル LLM と音声通話するシステムの仕上げ</li>
        <li>FAMと呼んでいるシステムの継続開発 or 作り直し</li>
        </ul>
        <p>一方で <a href="https://zenn.dev/hackathons/2024-google-cloud-japan-ai-hackathon">Zenn 主催のハッカソン</a> にも参加する予定なので、
        2月中旬まではそっちに集中する必要がありそう。</p>
        <p>相変わらず予定を詰め込む癖があります。</p>
        <h3>勉強</h3>
        <ul>
        <li>英語
        <ul>
        <li>初心に帰って英検、英語日記、NativeCampあたりをやる予定</li>
        </ul>
        </li>
        <li>数学
        <ul>
        <li>微積、統計、線形代数あたりを復習したい</li>
        </ul>
        </li>
        <li>Rust
        <ul>
        <li>まだ何もやってない</li>
        <li>本は買ってある</li>
        </ul>
        </li>
        <li>Kubernetes
        <ul>
        <li>本は買ってある</li>
        <li>自宅サーバーを k8s 化したい</li>
        </ul>
        </li>
        <li>RAG とか AI 関係
        <ul>
        <li>技術の進歩が早すぎて驚くばかり。AIエージェント（定義が曖昧だが）とかも作ってみたい</li>
        </ul>
        </li>
        </ul>
        <h3>DIY とか絵とか</h3>
        <p>家のサイズが 1/3 くらいになったので趣味用の机がなくなってしまいました。
        近所のコワーキングスペースが時間貸しでそれなりに安そうなので活用しようと思います。</p>
        <h3>論文</h3>
        <p>去年の１１月から情報処理学会に入って少し論文を読んでいます。
        自分でも書きたいので試行錯誤中</p>
        ]]>
      </content:encoded>
      <pubDate>Tue, 07 Jan 2025 15:00:01 GMT</pubDate>
    </item>
    <item>
      <title>Deno, Web Streams API で Local LLM と音声通話するWebシステムを開発している</title>
      <link>https://www.kbaba1001.com/posts/202412140705_making-a-talk-with-local-llm-system-with-deno-web-streams-api/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202412140705_making-a-talk-with-local-llm-system-with-deno-web-streams-api/</guid>
      <content:encoded>
        <![CDATA[<h2>開発中のもの</h2>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/LLjdWHjzwQU?si=YYHC0dihp1bLUwsT" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        <p>最近時々見かけるようになった、AIと音声通話できるやつを作ってみた。</p>
        <p>既存サービスとの違い、特徴としては</p>
        <ul>
        <li>外部APIを使わず、自宅サーバーのローカルGPUのみで動作</li>
        <li>Web Streams API を活用してリアルタイム処理を実現</li>
        <li>Backend: Deno, Hono, Kysely, PostgreSQL</li>
        <li>Frontend: Node, Vite, React</li>
        </ul>
        <h2>大まかなロジック</h2>
        <ul>
        <li>人間の声をブラウザのマイク機能で取得してサーバーに Web Streams で送る</li>
        <li>サーバー側で音声データを Faster Whisper を用いてテキスト化する</li>
        <li>テキストをリアルタイムにフロントエンドで取得</li>
        <li>テキストをローカルLLM (Ollama) にプロンプトとして渡す</li>
        <li>ローカルLLMからの実行結果をリアルタイムにフロントエンドに送信</li>
        <li>フロントエンドでテキストを読み上げ</li>
        </ul>
        <h2>リアルタイム処理</h2>
        <p>同期処理とかストリーミング処理などともいう。
        フロントエンドとバックエンドでデータのやり取りをする際に、少しずつデータを送ることでタイムラグを少なくしてシステムが動くようにする技術のこと。</p>
        <h3>リアルタイム処理の実装方法</h3>
        <p>Webシステムのリアルタイム処理について調べると WebSocket に関する情報がたくさん出てくる。</p>
        <h4>WebSocket のメリット・デメリット</h4>
        <ul>
        <li>WebSocket のメリット
        <ul>
        <li>sockert io などのライブラリを使うと簡単に実装できる</li>
        <li>古いブラウザでも動く</li>
        <li>使っている人が多いのかドキュメントが豊富</li>
        </ul>
        </li>
        <li>WebSocket のデメリット
        <ul>
        <li>双方向通信なので通信量が多い</li>
        <li>ws/wssというプロトコルを使うのでサーバー側で http/https とは別の設計が必要になる</li>
        </ul>
        </li>
        </ul>
        <h4>WebStreams のメリット・デメリット</h4>
        <ul>
        <li>WebStreams のメリット
        <ul>
        <li>単方向通信なので通信量を抑えることができる</li>
        <li>http/https で扱うことができるのでサーバーに特別な実装が不要</li>
        </ul>
        </li>
        <li>WebStreams のデメリット
        <ul>
        <li>使ってる人が少ないのかドキュメントが少ない（ほとんどMDNだけかも）</li>
        <li>古いブラウザでは動かないことがある</li>
        </ul>
        </li>
        </ul>
        <h4>今回は WebStreams を採用</h4>
        <p>WebStreams を使ったことがなかったのでやってみたかったというのが一番大きな理由（というかそのためにこのシステムを作っている）なのだが、WebSocketsは意外と気難しいやつだと思っていて、一見気楽に実装できて良いのだが本番環境まで含めて考えると通信量などの問題もあり使いこなすのが難しいという感触がある。</p>
        <h2>WebStreams API とは何か？</h2>
        <ul>
        <li>Readable Stream, Writable Stream, Transform Stream を使ってデータのやり取りができる。</li>
        <li>これらの Stream はシェルコマンドのように pipe してつなげることができるため、すっきりしたコードを書くことができて嬉しい。</li>
        <li>Web標準の機能であるから今どきのブラウザ、そしてDenoで活用することができる
        <ul>
        <li>Node.js は歴史的な経緯により Deno ほど綺麗な実装になっていない</li>
        </ul>
        </li>
        </ul>
        <p>詳しくは MDN 参照 <a href="https://developer.mozilla.org/en-US/docs/Web/API/Streams_API">https://developer.mozilla.org/en-US/docs/Web/API/Streams_API</a></p>
        <h2>WebStreams API はどこで使われているか？</h2>
        <ul>
        <li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Response">fetch の Response Body</a></li>
        <li><a href="https://hono.dev/docs/helpers/streaming">Hono の Streaming Helper</a></li>
        <li>Deno の IO や HTTP リクエストなど</li>
        </ul>
        <h2>作成するシステムの概要</h2>
        <p><img src="https://www.kbaba1001.com/img/posts/202412140705/design.png" alt="システムの概要図"></p>
        <h3>人の声をテキスト化する部分</h3>
        <p>フロント側の処理。音声データを取得してバックエンドに ReadableStream を使って送信する。</p>
        <pre><code class="language-ts">import { jwtTokenAtom } from &quot;@/atoms/current-user&quot;;
        import { httpClient } from &quot;@/libs/http-client&quot;;
        import { Box, Button } from &quot;@chakra-ui/react&quot;;
        import { useMutation } from &quot;@tanstack/react-query&quot;;
        import { useAtom } from &quot;jotai&quot;;
        import { useRef } from &quot;react&quot;;
        
        type AudioStreamerProps = {
        talkId: string;
        };
        
        export const AudioStreamer = ({ talkId }: AudioStreamerProps) =&gt; {
        // 音声データの取得用の Ref
        const mediaRecorderRef = useRef&lt;MediaRecorder | null&gt;(null);
        const streamControllerRef =
        useRef&lt;ReadableStreamDefaultController&lt;Uint8Array&gt; | null&gt;(null);
        const [jwtToken] = useAtom(jwtTokenAtom);
        
        const { mutate, isPending } = useMutation({
        mutationFn: async (audioStream: ReadableStream&lt;Uint8Array&gt;) =&gt; {
        return await httpClient({ jwtToken })
        .post(`talks/${talkId}/stream`, {
        body: audioStream,
        timeout: false,
        })
        .text();
        },
        onSuccess: (data) =&gt; {
        console.log(data);
        },
        onError: (error) =&gt; {
        console.error(error);
        },
        });
        
        // 音声データを取得してサーバーにリクエストする
        const startRecording = async () =&gt; {
        try {
        // マイクへのアクセスをリクエスト
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        // MediaRecorderの作成
        const options = {
        mimeType: &quot;audio/webm; codecs=opus&quot;, // サポートされているmimeTypeを指定
        };
        const mediaRecorder = new MediaRecorder(stream, options);
        
        mediaRecorderRef.current = mediaRecorder;
        
        // ReadableStreamの作成
        const audioStream = new ReadableStream&lt;Uint8Array&gt;({
        start(controller) {
        // コントローラを保存して、後でデータをエンキューする
        streamControllerRef.current = controller;
        },
        });
        
        // dataavailableイベントのハンドリング
        mediaRecorder.addEventListener(&quot;dataavailable&quot;, async (event) =&gt; {
        if (event.data &amp;&amp; event.data.size &gt; 0) {
        // BlobをArrayBufferに変換
        const arrayBuffer = await event.data.arrayBuffer();
        // ArrayBufferをUint8Arrayに変換
        const chunk = new Uint8Array(arrayBuffer);
        // ReadableStreamにチャンクをエンキュー
        streamControllerRef.current?.enqueue(chunk);
        }
        });
        
        // stopイベントのハンドリング
        mediaRecorder.addEventListener(&quot;stop&quot;, () =&gt; {
        // ReadableStreamをクローズ
        streamControllerRef.current?.close();
        });
        
        // 録音開始（100msごとにデータを収集）
        mediaRecorder.start(100);
        
        // ReadableStreamをAPIに送信
        mutate(audioStream);
        } catch (error) {
        console.error(&quot;マイクへのアクセスエラー:&quot;, error);
        }
        };
        
        const stopRecording = () =&gt; {
        mediaRecorderRef.current?.stop();
        };
        
        return (
        &lt;Box&gt;
        &lt;Button colorScheme=&quot;red&quot; onClick={startRecording} isLoading={isPending}&gt;
        録音
        &lt;/Button&gt;
        &lt;Button
        colorScheme=&quot;blue&quot;
        onClick={stopRecording}
        isDisabled={!isPending}
        &gt;
        停止
        &lt;/Button&gt;
        &lt;/Box&gt;
        );
        };
        </code></pre>
        <p>バックエンドでは、ReadableStreamを受け取って <a href="https://github.com/ufal/whisper_streaming">whisper_streaming</a> のサーバー（これは別途立ち上げておく）に音声データを渡し、テキストデータを受け取る。</p>
        <pre><code class="language-ts">app.post(&quot;/:id/stream&quot;, permissionChecker(&quot;talks&quot;), async (c) =&gt; {
        // 音声データをReadableStreamで取得する
        const stream = c.req.raw.body as ReadableStream;
        const talkId = Number(c.req.param(&quot;id&quot;));
        const user = c.get(&quot;currentUser&quot;);
        
        if (stream) {
        // whisper streaming は サンプリングレートなどに指定があるため FFmpeg で変換する
        // これは Web Streams API でパイプできる
        const ffmpeg = new Deno.Command(&quot;ffmpeg&quot;, {
        args: [
        &quot;-i&quot;,
        &quot;pipe:0&quot;, // 標準入力からデータを受け取る
        &quot;-ar&quot;,
        &quot;16000&quot;, // サンプリングレートを16000Hzに設定
        &quot;-ac&quot;,
        &quot;1&quot;, // モノラルに設定
        &quot;-sample_fmt&quot;,
        &quot;s16&quot;, // サンプルフォーマットをs16に設定
        &quot;-f&quot;,
        &quot;wav&quot;, // 出力フォーマットをWAVに設定
        &quot;pipe:1&quot;, // 標準出力にデータを出力
        ],
        stdin: &quot;piped&quot;,
        stdout: &quot;piped&quot;,
        stderr: &quot;piped&quot;,
        });
        const ffmpegProcess = ffmpeg.spawn();
        
        stream.pipeTo(ffmpegProcess.stdin);
        
        const convertedAudioStream = ffmpegProcess.stdout;
        
        // WhipserStreamingServer は TCP サーバーなので Deno.connect で接続できる
        // これも Web Streams でパイプできる
        const whisper = await Deno.connect({
        hostname: Deno.env.get(&quot;WHISPER_HOST&quot;) || &quot;localhost&quot;,
        port: Number(Deno.env.get(&quot;WHISPER_PORT&quot;)) || 43001,
        });
        
        convertedAudioStream.pipeTo(whisper.writable);
        
        const reader = whisper.readable.getReader();
        const decoder = new TextDecoder(&quot;utf-8&quot;);
        let sentence = &quot;&quot;;
        const sentenceIdentifier = crypto.randomUUID();
        
        try {
        // Streams からテキストデータを受け取って、DBに保存したり通知したりする
        while (true) {
        const { done, value } = await reader.read();
        if (done) {
        break;
        }
        const text = decoder.decode(value);
        // 先頭に数字が入っているので削除
        const wordText = text.replace(/^[\d\s]+/, &quot;&quot;).replace(/\n/g, &quot;&quot;);
        
        if (wordText.length &gt; 0) {
        sentence += wordText;
        // 後述のGETリクエストでテキストデータを取得できるようにするためにNotifyする
        await notify(&quot;words_inserted&quot;, {
        id: crypto.randomUUID(),
        talkId,
        userId: user.id,
        words: wordText,
        sentenceIdentifier,
        });
        await modelWords.create({
        talkId,
        userId: user.id,
        words: wordText,
        sentenceIdentifier,
        });
        }
        }
        } catch (error) {
        if (error instanceof Deno.errors.Interrupted) {
        customLogger(&quot;POST クライアントが接続を閉じました。&quot;);
        }
        }
        
        return c.text(&quot;completed&quot;, 200);
        }
        
        return c.text(&quot;ストリームが存在しません&quot;, 400);
        });
        </code></pre>
        <h3>新しいテキストができた時にフロントで取得する部分</h3>
        <p>フロントではAIと話すページを開いたときにバックエンドに対してGETリクエストを出して、
        過去の会話履歴を取得するようにしている。
        このリクエストをStreamで繋いだままにしておいて、新しいデータが入れば取得するようにしておく</p>
        <pre><code class="language-ts">	const [words, setWords] = useState&lt;Word[]&gt;([]);
        
        useEffect(() =&gt; {
        const fetchStream = async () =&gt; {
        // 次のエンドポイントはReadableStreamを返す
        const response = await httpClient({ jwtToken }).get(
        `talks/${talkId}/stream`,
        );
        const stream = response.body;
        
        if (!stream) {
        console.error(&quot;このブラウザはストリーミングをサポートしていません。&quot;);
        return;
        }
        
        const reader = stream.getReader();
        const decoder = new TextDecoder(&quot;utf-8&quot;);
        try {
        while (true) {
        const { done, value } = await reader.read();
        if (done) {
        console.log(&quot;done!&quot;);
        break;
        }
        
        // 新しいデータを受け取ったら Words 配列にいれる
        // (なるべく連続するデータは同じフキダシに入れたいのでちょっとコードがごちゃごちゃしている)
        const chunk = decoder.decode(value, { stream: true });
        const json = JSON.parse(chunk);
        const lastWord = json[0];
        if (lastWord?.assistantId != null) {
        speak(lastWord.words);
        }
        setWords((prev) =&gt; {
        const newArray = [...json, ...prev];
        const result = newArray.reduce((acc, cur) =&gt; {
        const key = cur.sentenceIdentifier;
        acc[key] = {
        id: key,
        userId: cur.userId,
        talkId: cur.talkId,
        words: acc[key]
        ? `${cur.words}${acc[key].words}`.replace(/\n/g, &quot;&quot;)
        : cur.words.replace(/\n/g, &quot;&quot;),
        sentenceIdentifier: key,
        };
        
        return acc;
        }, {});
        return Object.values(result);
        });
        }
        } catch (error) {
        console.error(&quot;ストリームの読み取り中にエラーが発生しました:&quot;, error);
        }
        };
        
        fetchStream();
        }, [jwtToken, talkId]);
        
        // words 配列を表示する処理が続く
        </code></pre>
        <p>バックエンドでは PostgreSQL の <a href="https://www.postgresql.org/docs/current/sql-notify.html">Notify/Listen</a> 機能を使って
        Channel のようなことをする。
        これにより、新しいデータが追加されたらフロントエンドに送る。</p>
        <pre><code class="language-ts">app.get(&quot;/:id/stream&quot;, permissionChecker(&quot;talks&quot;), async (c) =&gt; {
        const talkId = Number(c.req.param(&quot;id&quot;));
        
        const words = await modelWords.findAllByTalkId(talkId);
        const wordsJson = JSON.stringify(words);
        
        // stream を返すのでクライアントが接続を切らない限りデータを渡し続けることができる。
        return streamText(c, async (s) =&gt; {
        await s.writeln(wordsJson);
        // words_insterted という channel にJSONテキストが入ってくるのでそれを監視する
        // WARN channel 名に talkId を入れたほうが他の会話のデータを誤って取得せずに済みそう
        await listen(&quot;listen words_inserted&quot;, async (msg) =&gt; {
        if (msg.channel !== &quot;words_inserted&quot;) {
        return;
        }
        
        const word = JSON.parse(msg.payload);
        await s.write(JSON.stringify([word]));
        });
        
        s.onAbort(() =&gt; {
        customLogger(&quot;GET クライアントが接続を閉じました。&quot;);
        });
        
        while (true) {
        await s.sleep(1000);
        }
        });
        });
        </code></pre>
        <p>listen と notify 関数の実装は次のような感じ</p>
        <pre><code class="language-ts">import { CamelCasePlugin, Kysely, PostgresDialect, sql } from &quot;kysely&quot;;
        import Pool from &quot;pg-pool&quot;;
        import type { DB } from &quot;./database-types.ts&quot;;
        import { clerk } from &quot;./libs/clerk.ts&quot;;
        
        export const pool = new Pool({
        connectionString:
        Deno.env.get(&quot;DENO_ENV&quot;) === &quot;test&quot;
        ? Deno.env.get(&quot;TEST_DB_URL&quot;)
        : Deno.env.get(&quot;DATABASE_URL&quot;),
        max: 20,
        idleTimeoutMillis: 30000,
        connectionTimeoutMillis: 2000,
        });
        
        const dialect = new PostgresDialect({
        pool,
        });
        
        export const db = new Kysely&lt;DB&gt;({
        dialect,
        plugins: [new CamelCasePlugin()],
        log: (log) =&gt; {
        if (log.level === &quot;query&quot;) {
        clerk.info(&quot;SQL&quot;, log.query.sql);
        }
        },
        });
        
        export async function notify(channel: string, obj: object) {
        return await sql`select pg_notify(${channel}, ${JSON.stringify(obj)})`.execute(
        db,
        );
        }
        
        export async function listen(
        listenChannel: string,
        callback: (msg: { channel: string; payload: string }) =&gt; void,
        ) {
        const pgClient = await pool.connect();
        pgClient.on(&quot;notification&quot;, callback);
        
        return await pgClient.query(listenChannel);
        }
        </code></pre>
        <h3>Local LLM へのリクエストとレスポンス</h3>
        <p>会話データができたので、これをもとにプロンプトを作成してローカルLLMにリクエストする。</p>
        <pre><code class="language-ts">import { Button } from &quot;@chakra-ui/react&quot;;
        
        export function TalkToAI({
        assistantMutate,
        assistantIsPending,
        }: { assistantMutate: () =&gt; void; assistantIsPending: boolean }) {
        return (
        &lt;Button
        colorScheme=&quot;blue&quot;
        onClick={() =&gt; assistantMutate()}
        isLoading={assistantIsPending}
        &gt;
        AIをよびだす
        &lt;/Button&gt;
        );
        }
        
        // assistantMutate の中身
        const { mutate: assistantMutate, isPending: assistantIsPending } =
        useMutation({
        mutationFn: async () =&gt;
        await httpClient({ jwtToken }).post(`talks/${talkId}/assistant_chat`, {
        timeout: false,
        }),
        onSuccess: () =&gt; {
        //
        console.log(&quot;ok&quot;);
        },
        onError: (error) =&gt; {
        console.error(error);
        },
        });
        </code></pre>
        <p>現状、AI呼び出しのトリガーはボタンにしてある。
        将来的にはユーザーが話し終わったら自動で処理するようにしたい。</p>
        <p>バックエンドでは <code>talks/${talkId}/assistant_chat</code> にリクエストがあると、次の処理を行う。</p>
        <ul>
        <li>次の情報からLLMのプロンプトを作成する
        <ul>
        <li>直近数回の人間とAIの会話データ</li>
        <li>AIの人格設定データ</li>
        </ul>
        </li>
        <li>ローカルLLMサーバー (Ollama を使用) にプロンプトを投げる</li>
        <li>レスポンスをStreamで受け取り、DBにNotify、保存</li>
        </ul>
        <pre><code class="language-ts">app.post(&quot;/:id/assistant_chat&quot;, permissionChecker(&quot;talks&quot;), async (c) =&gt; {
        const talkId = Number(c.req.param(&quot;id&quot;));
        const user = c.get(&quot;currentUser&quot;);
        const talk = await modelTalks.findById({
        talkId,
        userId: user.id,
        });
        
        if (!talk) {
        return c.json({ message: &quot;Talk not found&quot; }, 404);
        }
        
        // 直近数回の会話を取得
        const words = await modelWords.findLatestByTalkId(talkId);
        
        // 人間とAIの会話によって role を切り替えながらLLMのプロンプトを作成
        let messages = words
        .map((word) =&gt; ({
        role: word.userId == null ? &quot;assistant&quot; : &quot;user&quot;,
        content: `${word.words}`,
        }))
        .reverse();
        
        // AIの人格設定は system role で渡す
        messages = [
        ...messages,
        { role: &quot;system&quot;, content: talk.assistant.personality },
        ];
        
        // Ollama で動いているローカルLLMにリクエストする
        const response = await ky.post(`${Deno.env.get(&quot;OLLAMA_URL&quot;)}/api/chat`, {
        json: {
        model: talk.assistant.model,
        messages,
        stream: true,
        },
        });
        
        // ローカルLLMサーバーからのレスポンスをchannelに通知したり、保存したりする
        const reader = response.body?.getReader();
        const decoder = new TextDecoder(&quot;utf-8&quot;);
        const sentenceIdentifier = crypto.randomUUID();
        let text = &quot;&quot;;
        let textChank = &quot;&quot;;
        while (reader &amp;&amp; true) {
        const { done, value } = await reader.read();
        if (done) {
        break;
        }
        const jsonText = decoder.decode(value, { stream: true });
        const json = JSON.parse(jsonText);
        
        textChank += json.message.content;
        if (textChank.length &gt; 20) {
        await notify(&quot;words_inserted&quot;, {
        id: crypto.randomUUID(),
        talkId: talk.id,
        assistantId: talk.assistantId,
        words: textChank,
        sentenceIdentifier,
        });
        
        text += textChank;
        textChank = &quot;&quot;;
        }
        }
        
        if (textChank.length &gt; 0) {
        await notify(&quot;words_inserted&quot;, {
        id: crypto.randomUUID(),
        talkId: talk.id,
        assistantId: talk.assistantId,
        words: textChank,
        sentenceIdentifier,
        });
        
        text += textChank;
        textChank = &quot;&quot;;
        
        await modelWords.create({
        talkId,
        assistantId: talk.assistantId,
        words: text,
        sentenceIdentifier,
        });
        }
        
        return c.json({ msg: text });
        });
        </code></pre>
        <h3>AIからのレスポンステキストの読み上げ</h3>
        <p>ひとまずブラウザの機能で読み上げているだけ</p>
        <pre><code class="language-ts">function speak(text: string) {
        // SpeechSynthesisUtteranceのインスタンスを作成
        const utterance = new SpeechSynthesisUtterance();
        utterance.text = text;
        utterance.lang = &quot;ja-JP&quot;;
        // 音声を再生
        window.speechSynthesis.speak(utterance);
        }
        </code></pre>
        <p>新しいテキストを取得した際に、AIからの発言であれば上記の関数を使って読み上げる。</p>
        <h2>今後の展望</h2>
        <p>テキスト読み上げが地味なので <a href="https://github.com/VOICEVOX/voicevox_engine">VOICEVOX</a> などをつかって音声データをサーバーで作成し、
        フロントに送るようにしたい。
        これもStreamを利用してリアルタイムにやりたいので、そんな感じの仕組みを作成中。</p>
        <p>すべてのソースコードの公開は全体が完成したらします。</p>
        ]]>
      </content:encoded>
      <pubDate>Sat, 14 Dec 2024 07:05:34 GMT</pubDate>
    </item>
    <item>
      <title>Clojure Family が色々ある話</title>
      <link>https://www.kbaba1001.com/posts/202412030751_clojure-family/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202412030751_clojure-family/</guid>
      <content:encoded>
        <![CDATA[<p>Clojure といえば JVM 上で動く Lisp のように紹介されることが多く、
        私もそういう言い方をすることも多いのだがこの言い方は正しくない。
        なぜなら JVM 以外で動く Clojure (あるいは Clojure っぽい言語も含む) が多々存在しているからだ。</p>
        <p>今日は Clojure Family とも言うべきこれらの方言について紹介する。</p>
        <h2>Clojure (JVMで動くやつ)</h2>
        <p>まずは一番良く使われている JVM 上で動く Clojure 。
        特筆されない場合 &quot;Clojure&quot; といえばこれのこと。</p>
        <ul>
        <li>Java の機能やエコシステムを活用したい場合はとてもよい</li>
        <li>とりあえず Clojure を使いたい場合はこれがおすすめ</li>
        </ul>
        <h2>ClojureScript (Alt JS の一種)</h2>
        <p>ビルドすると JavaScript になる Clojure 。
        おそらく JVM 版の次によく使われている。
        JVM 版と同じところが開発しているという安心感がある。</p>
        <p>ただ、ビルドツールが色々とあって、</p>
        <ul>
        <li><a href="https://clojurescript.org/guides/quick-start">deps.ednを使う方法</a></li>
        <li><a href="https://figwheel.org/">Figwheel</a></li>
        <li><a href="https://github.com/thheller/shadow-cljs">Shadow-cljs</a></li>
        </ul>
        <p>などのやり方がある。</p>
        <p>「deps.edn を使う方法」は公式サイトに乗っているやり方だが、これは npm ライブラリを素直に使えないというデメリットが有り、
        そのへんを解決するために後者の 2 つがある。</p>
        <p>Shadow-cljs が一番後発なので、今から新しく何かを作りたいなら、これがおすすめ。
        （あるいは後述の squint や cherry を使う）</p>
        <h2>ClojureCLR</h2>
        <p>こちらも Clojure 本家が作成しているもので、 ビルドすると Microsoft’s .Net Framework 環境で動く Clojure 。
        つまり C# で書かれた Clojure 実装。</p>
        <p>私は使ったことがなく、詳しくないので紹介する程度に留める。
        ゲームとかWindowsサーバーでClojureを使いたい人にはいいのかもしれない。</p>
        <h2>Babashka</h2>
        <p><a href="https://babashka.org/">Babashka</a> は GraalVM を用いて Clojure を native binary にビルドできるもの。</p>
        <p>JVM 版の Clojure を使うとどうしても実行時の起動に時間が掛かるが、 Babashka であればすぐに動くので
        スクリプトを Clojure で書きたい場合などに便利。</p>
        <p><a href="https://github.com/borkdude">Michiel Borkent</a> 氏の作品。彼は Babashka を始め後述の様々なツールを作っているすごい人。</p>
        <h2>Squint</h2>
        <p><a href="https://github.com/squint-cljs/squint">squint</a> は ClojureScript のコンパイラなのだが、 JavaScript の Built-in Data structures のみ使用しているため、いくつかの点で本来の ClojureScript とは異なる。</p>
        <ul>
        <li>ClojureScript では <code>[]</code> や <code>{}</code> は JavaScript のオブジェクトではなく immutable な ClojureScript ようにカスタムされたオブジェクトを返すが、 Squint では JavaScript の build-in の <code>Array</code> や <code>Object</code> を返す。</li>
        <li>Async/Await のサポート (ClojureScript では core.async などを使う必要があったが Squint では Promise が素直に使える)</li>
        <li>ClojureScript 用に開発されたライブラリなどがうまく動かない場合があるので、JS/TS用のライブラリを使うほうが無難</li>
        <li><a href="https://github.com/brandonstubbs/vite-plugin-squint">vite-plugin-squint</a> などを使うと Squint -&gt; JSX -&gt; JS の変換が楽</li>
        </ul>
        <p>Squint はないよりも気軽に CLJS （っぽい言語）が使えるのが魅力。
        私としてはかなり期待している。</p>
        <h2>Cherry</h2>
        <p><a href="https://github.com/squint-cljs/cherry">Cherry</a> は Squint よりもともとの ClojureScript への互換性を高めたもの。
        ClojureScript のライブラリを活用したい場合はこちらのほうが良さそう。</p>
        <h2>Jank</h2>
        <p><a href="https://jank-lang.org/">Jank</a> は Clojure を LLVM + JIT コンパイラで動くようにしたもの。
        C++との親和性が高いらしく、C/C++ っぽい領域のところを Clojure で書きたい場合には良さそう。
        どのくらいの事ができるのかをまだ私は把握しきれていないけど、将来性はあるように思うので期待。</p>
        <h2>その他</h2>
        <p>私は使ったことないけど他のClojure方言を紹介</p>
        <ul>
        <li><a href="https://github.com/Tensegritics/ClojureDart">ClojureDart</a></li>
        <li><a href="https://github.com/clojerl/clojerl">ClojureL</a>
        <ul>
        <li>Erlang 実装</li>
        </ul>
        </li>
        <li><a href="https://github.com/kanaka/mal">mal</a>
        <ul>
        <li>Clojure っぽい言語を実装することで言語実装について学ぶプロジェクト</li>
        </ul>
        </li>
        </ul>
        <h2>感想</h2>
        <p>Lisp は方言がたくさんある言語だけど、最近はもうClojure方言と呼ぶべき分野ができていて、
        やっぱりClojureの人気はすごいなぁと思ったりしました。
        Scheme方言なんかも結構たくさんあるみたいで調べてみると面白かったです。</p>
        ]]>
      </content:encoded>
      <pubDate>Tue, 03 Dec 2024 07:51:05 GMT</pubDate>
    </item>
    <item>
      <title>渋谷でもくもく会に参加した</title>
      <link>https://www.kbaba1001.com/posts/202411030733_attended-shibuya-mokumoku/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202411030733_attended-shibuya-mokumoku/</guid>
      <content:encoded>
        <![CDATA[<p><img src="https://www.kbaba1001.com/img/posts/202411030733/mokumoku.jpg" alt="渋谷でもくもく会"></p>
        <p><a href="https://connpass.com/event/334713/">渋谷でもくもく会</a> に参加してきた。</p>
        <p>こういうイベントに参加するのは久しぶりで楽しかった。</p>
        <h3>会の雰囲気</h3>
        <p>シェアオフィスでの開催だったので静かな空間で良かった。
        参加者も１０人くらいで適度におしゃべりしたりするのにちょうどいい感じ。</p>
        <p>もくもく会だが、作業したり喋ったりゆるい雰囲気で良かった。
        （ずっと黙っている会もあったりするが、自分好みではない）</p>
        <p>他の参加者は若手と中堅のエンジニアの方が半々くらいで、
        適度に会話が盛り上がって楽しかった。
        意外と女性の参加者も多かった。</p>
        <p>私は最近静岡に引きこもっているので、Tech系の話をするのは久々で
        自分がこういうおしゃべりに飢えていたことに気づいた。</p>
        <p>若手エンジニアの方たちの話は自分にとっては新鮮なところもあって、
        転職の話とかどのように技術を学んでいくかとか、話題が若くて良かった。</p>
        <h3>やっていたこと</h3>
        <p>最近 ChatGPT に AI と音声で会話できる機能がついたのだが、それと同じようなものを
        ローカルLLMを使って実現したい。次の流れで実現できると思っている。</p>
        <ul>
        <li>ユーザーの音声のテキスト化
        <ul>
        <li>ユーザーの音声をブラウザで取得</li>
        <li>音声データをStreamでサーバーにおくる</li>
        <li>サーバーでは音声データをWhisperで文字に変換する (ここもStream処理)</li>
        <li>文字データをフロント側にStreamで返却しつつ、DBにも保存する</li>
        </ul>
        </li>
        <li>テキストをローカルLLMにわたして返答をつくる
        <ul>
        <li>１００文字くらいの短い文章を作るように命令しておく</li>
        <li>インプットはStreamではなくまとめてテキストデータを入れる</li>
        <li>アウトプットをStream で受け取る</li>
        </ul>
        </li>
        <li>LLMの返答を音声データにする
        <ul>
        <li>LLMのアウトプットを Stream で受け取り、それを <a href="https://github.com/KoljaB/RealtimeTTS">RealtimeTTS</a> などを用いて Stream で音声データにする</li>
        <li>サーバーからフロントに音声データと文字データを Stream で送る</li>
        <li>フロントではサーバーからのレスポンスを Stream で受け取りつつ、音声を再生し、文字データを画面に表示する</li>
        </ul>
        </li>
        </ul>
        <p>もくもく会では、ブラウザ上で音声データを取得して ReadableStream でサーバーに送り、
        サーバー側でファイル化するという処理を作ることができた。</p>
        <p>実際には受け取ったバイナリをファイルにするんじゃなくて、そのまま <a href="https://github.com/ufal/whisper_streaming/blob/main/whisper_online_server.py">whisper_online_server.py</a> に渡してテキスト化したい。</p>
        <h3>結果</h3>
        <p>会場ではかなり集中して作業できてきちんとした進捗が出せてよかった。</p>
        <p>12:00 - 18:30 （わたしは 17:30 で帰ったけど）という長時間の会だったので、
        なかなか普段ここまでまとまった時間は取れないので、それだけでもありがたかった。</p>
        <h3>蛇足: わからないことをAIに聞くことに慣れた</h3>
        <p>会とは関係ないけど WebStream API をつかったコーディングは初めてで
        MDNのサンプルコードだけだとしんどいなぁと思っていたところ、
        ChatGPTにサンプルコードを提示させるとかなりいいコードがでてきて、
        なんかもうこれでいいじゃんとなった。
        こういう規格に沿ったものをつくるのはAIのほうが得意そうだ。</p>
        <p>バックエンドも Deno にしているので Web 標準の機能が使えてスッキリするが、
        これも資料が少ないので ChatGPT に聞いたほうが何かと早い。。。</p>
        <p>ChatGPTの作ったコードをとりあえず動かしてみて、問題があったらドキュメントを参考に修正するという感じ。</p>
        <p>すごい時代になったなぁ。。。</p>
        ]]>
      </content:encoded>
      <pubDate>Sun, 03 Nov 2024 07:33:24 GMT</pubDate>
    </item>
    <item>
      <title>ここ数年について</title>
      <link>https://www.kbaba1001.com/posts/202410291201_recently-a-few-years/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202410291201_recently-a-few-years/</guid>
      <content:encoded>
        <![CDATA[<p>最近何やってるの？、をざっくりまとめる。</p>
        <h3>プログラミング、絵、その他</h3>
        <p>以前にもまして家にこもりがちで、相変わらずプログラムを書いている。
        絵もたまに書いている。</p>
        <p>なんか自分の中の行動としてこの２つで固めていこうという感じがしている。</p>
        <p>プログラミングは以前にもまして他の人に説明しづらくなってきた。
        Clojureも時々は書いていて、TypeScriptも渋々とはいえ使い慣れてしまったほどには書いている。
        TSに関してはGoよりは書きやすく、仕事で使うならこれでいいかなぁーという感じがある。
        一人で書くコードに関してはなるべくClojureを使いたいが、それも結構面倒くさくて結局TSで書いていることも多い。</p>
        <p>プログラミング以外のIT系のこととしては自宅サーバーを始めたり、ローカルLLMで遊んだりしている。
        自宅サーバーの話はこのブログでもたまに書いているけど、そろそろ docker compose で色々やるのが限界なので
        k8s でも導入しようかと思っている。
        年末年始に少し自宅サーバーのパーティションなども整理したいと思いつつ、どうなることやら。</p>
        <p>AIに関してはわくわく感より恐ろしさのほうが強くていまいち熱中しきれないでいる。
        将来的にプログラムを手で書くような時代は終わってしまうのかもしれないと思うと淋しい。
        ChatGPTなども使っているがやはりローカルで動かしたいのでローカルLLMの研究をすることが多い。</p>
        <h3>辞めることを覚えようとしている</h3>
        <p>気がつけば３５歳になっていた。気持ち的には２０台後半くらいから何も変わってないのだが、
        体は明らかに代謝・体力など落ちていて、以前ほど集中力も続かなくなった。</p>
        <p>何より、眠い。</p>
        <p>夜起きていられない。19時ごろには眠っていることが多い。
        で、朝は3, 4時頃起きている。</p>
        <p>そんなわけで、なるべくやりたいことを減らすように努力しようと家族会議で決まった。
        やりたいことを絞って、なるべくゆっくり暮らすように心がけたい。</p>
        <p>ちょっと今まで忙しくしすぎた。</p>
        <h3>生活のこと</h3>
        <h4>近所付き合い</h4>
        <p>静岡県三島市に引っ越して早くも３，４年くらい経っている。
        生活は落ち着いてきた。引っ越し当初はコロナ禍で近所付き合いもなかったが、
        最近は町内会の組長をやっている都合もあり、少しは近所の人とも関わるようになった。
        具体的にはお祭りでかき氷を売ったりとか。それなりに楽しくやっている。</p>
        <h4>外食と酒</h4>
        <p>東京で暮らしていた頃に比べると、明らかに外食が減っている。
        とくに外で酒を飲むと代行代が結構かかるので、もっぱら宅飲みになった。
        その酒も以前よりはかなり減っていて、月に２，３回程度。
        一度飲むと少し飲みすぎるきらいがあるけど、飲まないときは数ヶ月飲まないこともある。</p>
        <h4>SNS、友人関係</h4>
        <p>去年くらいに X (Twitter) や Instagram などあらかたアカウントを消してしまって、Facebookもほぼ見なくなった。
        なんかインターネットに疲れた。SNSをやる楽しさより、知らない人の怒りみたいなものに触れることが増えてなんか嫌になってしまった。
        炎上みたいなのも別に自分の生活には関係ないことが多いし、ニュースも陰鬱な話題が多いし。</p>
        <p>代わりにやっているインターネットと言えば、 Discord でエンジニアとか絵描きさんとかと話をさせてもらっている。
        Discord は変に拡散されたりしない安心感がある（とはいえ公共の場ではあるが）。</p>
        <p>あとは zenn.dev の新しい記事を時々見たりしている程度だが、新しい情報のキャッチアップは思ったより困ってない気がする。</p>
        <p>友人関係は２０代の知り合いは結婚したり引っ越したりでみな生活が変わってしまった感じがしていて、
        自分も人のことは言えず三島に引きこもっているわけで、時の流れを感じることが多く、やや淋しい。</p>
        <p>特にTech系の話題を気楽にできていた２０代の頃を思い起こすと、今はなんだかなぁという感じもする。
        自分の興味のあるTechの話がマイナーになりすぎたのもあるし、勉強会とか行かなくなったのもあるし。</p>
        <p>東京を離れて三島に来たことは本当に良かったと思っているが、
        コミュニティとの関わり方みたいなのはもう少しやり方を覚えたいなぁと思ったりしている。</p>
        <h3>古い人間関係が復活したり</h3>
        <p>一方で、この5年間で実家には２度帰った。一生帰るつもりがなかったことを考えればすごいことだと思うが、
        やはり実家の人間関係は自分にはしんどくてもう十分かなぁという気持ちもある。
        兄とはたまにLINEしている。２０代の頃は考えられなかったことなので成長だと思うことにする。</p>
        <p>しばらく前に、高校の時の知り合いにもあった。飲み会を開いてくれて楽しかった。
        同じIT業界にいるせいか、世間が狭いのか、全く関係ないところで知り合った共通の知人が数名いて不思議だった。</p>
        <p>シェアハウス仲間にも久々に会ったりした。
        東京にいる人にはやはり会いやすいけど、地方の人には合う機会は減るもののつながりはなんとか続いている。
        地方で会えるとなんか楽しい。三島にも来てもらえたらやっぱり嬉しいし。</p>
        ]]>
      </content:encoded>
      <pubDate>Tue, 29 Oct 2024 12:01:11 GMT</pubDate>
    </item>
    <item>
      <title>近々やりたいこと2024年10月</title>
      <link>https://www.kbaba1001.com/posts/202410200712_what-I-will-do-from-2024-10/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202410200712_what-I-will-do-from-2024-10/</guid>
      <content:encoded>
        <![CDATA[<p>近々やりたいこと</p>
        <ul>
        <li>ClojureScript (Squint) 関係の動画
        <ul>
        <li>プログラミングしながら雑談するような、プログラミング Vlog 動画を作りたい</li>
        </ul>
        </li>
        <li>Ollama か llama-cpp-python をベースにしてローカル AI と日本語で音声通話できる仕組みを作りたい
        <ul>
        <li>喋った言葉を whisper でテキスト化してローカルllm に認識させて、その結果を VOICEVOX で読み上げさせる</li>
        <li>Ollama は JS 対応されているのでうまいことクライアント作れば良さそう
        <ul>
        <li>とりあえず Web ベースのクライアントで良い</li>
        <li>コードも理解させるなら VS Code プラグインが理想かもしれない</li>
        </ul>
        </li>
        <li>以前から作っているローカルAI: Poppins システムの発展型</li>
        </ul>
        </li>
        <li>Supabase (Self-host) + Deno Fresh + Squint でシステム構築
        <ul>
        <li>以前から作っている FAM システムの作り直し</li>
        <li>ロードバランサ (Kong か Caddy あたり) をうまく使って拡張できるようにしたい</li>
        <li>今まで特定のサービスに依存しないシステム開発を心がけてきたけど、次の理由でSupabase依存することにした
        <ul>
        <li>PGroonga が動くクラウドシステムは Supabase のみ</li>
        <li>Supabase が self-host できるので必ずしもクラウド依存ではない</li>
        <li>Supabase 使うほうが認証とかストレージとか楽そう</li>
        </ul>
        </li>
        <li>Deno Fresh について
        <ul>
        <li>React より Preact のほうが好み</li>
        <li>Preact 前提なら vite で頑張るより Fresh 使うほうが楽かも</li>
        <li>サーバーサイドが Supabase 前提で簡略化出来るなら backend と frontend を分けなくても良さそう</li>
        </ul>
        </li>
        <li>Squint について
        <ul>
        <li>Squint で js, jsx を出力してそれを Deno Fresh で動かせれば理想</li>
        <li>もちろん Squint 使わないほうが一般的だし楽だけども、やはり Clojure を書きたい</li>
        </ul>
        </li>
        </ul>
        </li>
        <li>技術書典 (11/3) 参加予定
        <ul>
        <li>自宅サーバー本が出ます</li>
        <li>ローカル AI 本も出るかも？間に合えば…</li>
        </ul>
        </li>
        <li>ISUCON
        <ul>
        <li>参加申込済みだけどいまいち練習できていない。やらねば。。。</li>
        </ul>
        </li>
        <li>Rust の勉強
        <ul>
        <li>ISUCON 終了後に着手できそう</li>
        <li>本を3冊買ってあるので勉強したい</li>
        <li>特に WASM とか Web 対応とかが気になる</li>
        </ul>
        </li>
        <li>自宅サーバーに関する動画作成
        <ul>
        <li>自宅サーバー + NextCloud の話をもう少ししたい</li>
        <li>自宅サーバー + Local LLM の話もしたい</li>
        </ul>
        </li>
        </ul>
        <hr>
        <p>上記の箇条書きを ChatGPT 4o with canvas で文章化しました。↓</p>
        <hr>
        <p>やりたいことがたくさんあってワクワクしているので、近々取り組みたいプロジェクトについてまとめてみました。</p>
        <h3>ClojureScript (Squint) 関連の動画</h3>
        <p>ClojureScriptの一環として、特に&quot;Squint&quot;に関係するプログラミングのVlog動画を作りたいと思っています。プログラミングをしながら雑談をするような形式で、リラックスした雰囲気の動画になる予定です。技術的な内容と日常的な思考を共有することで、視聴者の皆さんと同じ熱意を共有できると嬉しいです。</p>
        <h3>ローカルAIと日本語で音声通話する仕組み</h3>
        <p>次に取り組みたいのが、Ollamaやllama-cpp-pythonをベースにして、ローカルAIと日本語で音声通話できる仕組みの開発です。これは、話した言葉をWhisperでテキスト化し、その内容をローカルのLLM（大規模言語モデル）に理解させ、その結果をVOICEVOXで読み上げる、という流れを想定しています。特にOllamaはJavaScript対応されているので、Webベースのクライアントを作ってテストしてみたいと思っています。最終的にはVS Codeプラグインとして、コードも理解する形に進化させるのが理想です。このアイデアは以前から作っているローカルAI、&quot;Poppinsシステム&quot;の発展型と考えています。</p>
        <h3>Supabase + Deno Fresh + Squint でシステム構築</h3>
        <p>次に、Supabase（Self-host）とDeno Fresh、そしてSquintを使って新たなシステム構築に取り組もうと思っています。このプロジェクトは、以前から作っているFAMシステムの改良版です。ロードバランサ（KongやCaddyなど）を使って、より拡張性のあるシステムにすることが目標です。</p>
        <p>これまで私は、特定のサービスに依存しないシステム開発を心がけてきましたが、以下の理由でSupabaseを選びました。</p>
        <ul>
        <li>PGroongaが動作するクラウドシステムはSupabaseのみ</li>
        <li>Supabaseはセルフホスト可能で、必ずしもクラウドに依存しない</li>
        <li>認証やストレージなどが簡単に利用できる</li>
        </ul>
        <p>Deno Freshを使う理由としては、Reactよりも軽量なPreactが好みであり、Preact前提ならFreshのほうがシンプルに開発できそうだからです。また、バックエンドとフロントエンドを分ける必要もないため、全体の開発が楽になると考えています。</p>
        <p>Squintについては、JavaScriptやJSXを生成してDeno Freshで動かすことを目指しています。もちろんSquintを使わないほうが一般的ではありますが、それでもClojureを書く楽しさを手放したくない気持ちがあります。</p>
        <h3>技術書典への参加</h3>
        <p>11月3日に開催される技術書典に参加する予定です。そこで、自宅サーバーに関する本を出す予定です。さらに、ローカルAIに関する本も間に合えば出したいと考えています。</p>
        <h3>ISUCONの参加</h3>
        <p>ISUCONに申し込んでいますが、まだあまり練習できていません。本番に向けてもう少し頑張って準備しなければと感じています。</p>
        <h3>Rustの勉強</h3>
        <p>ISUCONが終わったら、Rustの勉強にも取り組みたいと思っています。すでに3冊の本を購入しているので、これらを活用して特にWASMやWeb関連の技術に注目しながら学んでいく予定です。</p>
        <h3>自宅サーバーに関する動画作成</h3>
        <p>最後に、自宅サーバーに関する動画も作成したいと考えています。特に、自宅サーバーとNextCloudの設定や、自宅サーバーとローカルLLMの連携についてもう少し掘り下げて共有したいです。</p>
        <p>こうしてみると、たくさんのプロジェクトがありますが、どれも非常に楽しみで取り組むのが待ち遠しいです。少しずつ進めて、ブログや動画で進捗を共有していければと思っています。</p>
        <p>《kbaba1001|/img/horse.jpg|普通に読める文章になっていて恐ろしい...》</p>
        <hr>
        <p>ちなみに、同じプロンプトで llama3-elyza-jp-8b を実行した結果は次:</p>
        <hr>
        <p>タイトル: 近々やりたいことのまとめ - プログラミングとローカルAIの活用 -</p>
        <p>近いうちに取り組みたいプロジェクトや活動について、箇条書きで整理してみました。以下はその内容です。</p>
        <p>先日、技術書典11/3に参加し、自宅サーバー本を出します。同時に、ローカルAI本も出る予定です。他にも、ISUCONやRustの勉強、ClojureScriptやOllamaを活用したローカルAIと音声通話、SupabaseやDeno Freshを使用したシステム構築など多くのプロジェクトが控えています。</p>
        <p>以下は、各プロジェクトの詳細です。</p>
        <ol>
        <li>
        <p>ClojureScript関係の動画:
        プログラミングしながら雑談するVlog動画を作りたい。Ollamaやllama-cpp-pythonを使用し、ローカルAIと日本語で音声通話できる仕組みを構築します。</p>
        </li>
        <li>
        <p>Ollamaやllama-cpp-pythonのクライアント作成:
        Webベースのクライアントを作る予定です。VS Codeプラグインが理想かもしれません。</p>
        </li>
        <li>
        <p>Supabase、Deno Fresh、Squintでのシステム構築:
        以前から作っているFAM システムをSupabaseで再構築します。ロードバランサを使って拡張できるようにし、認証やストレージを楽に設定したいです。</p>
        </li>
        <li>
        <p>Deno Freshについて:
        Preactを使用してFreshでアプリケーションを作成する予定です。サーバー側の設定が簡略化されるならば、backendとfrontendを分ける必要はなさそうです。</p>
        </li>
        <li>
        <p>Squintについて:
        Squintでjs,jsxを出力し、Deno Freshで動かすことが理想です。もちろん一般的にはClojureScriptを使わないほうが楽ですが、書きたいから使います。</p>
        </li>
        <li>
        <p>技術書典11/3の参加と自宅サーバー本の出版:
        自宅サーバー本を出します。ローカルAI本も出る予定です。</p>
        </li>
        <li>
        <p>ISUCONの参加申し込みとRustの勉強:
        ISUCONに参加申込済みですが、練習できていません。やらねばです。Rustの勉強は、ISUCON終了後から始める予定です。</p>
        </li>
        <li>
        <p>自宅サーバーに関する動画作成:
        自宅サーバーとNextCloudやローカルLLMについての話をまとめたいです。</p>
        </li>
        </ol>
        <p>以上が近々やりたいことの内容です。</p>
        <p>《kbaba1001|/img/horse.jpg|要約してくれた感じだね》</p>
        <p>やはり llama2 系に比べれば圧倒的に進歩しているけど、 ChatGPT 4o にはもちろん及ばず。
        でもこれくらい動けばなにかできそうではある。</p>
        ]]>
      </content:encoded>
      <pubDate>Sun, 20 Oct 2024 07:12:38 GMT</pubDate>
    </item>
  </channel>
</rss>