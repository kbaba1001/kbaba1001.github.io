<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" version="2.0">
  <channel>
    <title>ハッカーと漫画家</title>
    <link>https://www.kbaba1001.com/</link>
    <atom:link href="https://www.kbaba1001.com/feed.rss" rel="self" type="application/rss+xml"/>
    <description>Clojure 好きなプログラマ kbaba1001 のブログ</description>
    <lastBuildDate>Sun, 17 Dec 2023 15:00:00 GMT</lastBuildDate>
    <language>ja_JP</language>
    <generator>Lume v2.0.1</generator>
    <item>
      <title>Deno, Web Streams API で Local LLM と音声通話するWebシステムを開発している</title>
      <link>https://www.kbaba1001.com/posts/202412140705_making-a-talk-with-local-llm-system-with-deno-web-streams-api/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202412140705_making-a-talk-with-local-llm-system-with-deno-web-streams-api/</guid>
      <content:encoded>
        <![CDATA[<h2>開発中のもの</h2>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/LLjdWHjzwQU?si=YYHC0dihp1bLUwsT" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        <p>最近時々見かけるようになった、AIと音声通話できるやつを作ってみた。</p>
        <p>既存サービスとの違い、特徴としては</p>
        <ul>
        <li>外部APIを使わず、自宅サーバーのローカルGPUのみで動作</li>
        <li>Web Streams API を活用してリアルタイム処理を実現</li>
        <li>Backend: Deno, Hono, Kysely, PostgreSQL</li>
        <li>Frontend: Node, Vite, React</li>
        </ul>
        <h2>大まかなロジック</h2>
        <ul>
        <li>人間の声をブラウザのマイク機能で取得してサーバーに Web Streams で送る</li>
        <li>サーバー側で音声データを Faster Whisper を用いてテキスト化する</li>
        <li>テキストをリアルタイムにフロントエンドで取得</li>
        <li>テキストをローカルLLM (Ollama) にプロンプトとして渡す</li>
        <li>ローカルLLMからの実行結果をリアルタイムにフロントエンドに送信</li>
        <li>フロントエンドでテキストを読み上げ</li>
        </ul>
        <h2>リアルタイム処理</h2>
        <p>同期処理とかストリーミング処理などともいう。
        フロントエンドとバックエンドでデータのやり取りをする際に、少しずつデータを送ることでタイムラグを少なくしてシステムが動くようにする技術のこと。</p>
        <h3>リアルタイム処理の実装方法</h3>
        <p>Webシステムのリアルタイム処理について調べると WebSocket に関する情報がたくさん出てくる。</p>
        <h4>WebSocket のメリット・デメリット</h4>
        <ul>
        <li>WebSocket のメリット
        <ul>
        <li>sockert io などのライブラリを使うと簡単に実装できる</li>
        <li>古いブラウザでも動く</li>
        <li>使っている人が多いのかドキュメントが豊富</li>
        </ul>
        </li>
        <li>WebSocket のデメリット
        <ul>
        <li>双方向通信なので通信量が多い</li>
        <li>ws/wssというプロトコルを使うのでサーバー側で http/https とは別の設計が必要になる</li>
        </ul>
        </li>
        </ul>
        <h4>WebStreams のメリット・デメリット</h4>
        <ul>
        <li>WebStreams のメリット
        <ul>
        <li>単方向通信なので通信量を抑えることができる</li>
        <li>http/https で扱うことができるのでサーバーに特別な実装が不要</li>
        </ul>
        </li>
        <li>WebStreams のデメリット
        <ul>
        <li>使ってる人が少ないのかドキュメントが少ない（ほとんどMDNだけかも）</li>
        <li>古いブラウザでは動かないことがある</li>
        </ul>
        </li>
        </ul>
        <h4>今回は WebStreams を採用</h4>
        <p>WebStreams を使ったことがなかったのでやってみたかったというのが一番大きな理由（というかそのためにこのシステムを作っている）なのだが、WebSocketsは意外と気難しいやつだと思っていて、一見気楽に実装できて良いのだが本番環境まで含めて考えると通信量などの問題もあり使いこなすのが難しいという感触がある。</p>
        <h2>WebStreams API とは何か？</h2>
        <ul>
        <li>Readable Stream, Writable Stream, Transform Stream を使ってデータのやり取りができる。</li>
        <li>これらの Stream はシェルコマンドのように pipe してつなげることができるため、すっきりしたコードを書くことができて嬉しい。</li>
        <li>Web標準の機能であるから今どきのブラウザ、そしてDenoで活用することができる
        <ul>
        <li>Node.js は歴史的な経緯により Deno ほど綺麗な実装になっていない</li>
        </ul>
        </li>
        </ul>
        <p>詳しくは MDN 参照 <a href="https://developer.mozilla.org/en-US/docs/Web/API/Streams_API">https://developer.mozilla.org/en-US/docs/Web/API/Streams_API</a></p>
        <h2>WebStreams API はどこで使われているか？</h2>
        <ul>
        <li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Response">fetch の Response Body</a></li>
        <li><a href="https://hono.dev/docs/helpers/streaming">Hono の Streaming Helper</a></li>
        <li>Deno の IO や HTTP リクエストなど</li>
        </ul>
        <h2>作成するシステムの概要</h2>
        <p><img src="https://www.kbaba1001.com/img/posts/202412140705/design.png" alt="システムの概要図"></p>
        <h3>人の声をテキスト化する部分</h3>
        <p>フロント側の処理。音声データを取得してバックエンドに ReadableStream を使って送信する。</p>
        <pre><code class="language-ts">import { jwtTokenAtom } from &quot;@/atoms/current-user&quot;;
        import { httpClient } from &quot;@/libs/http-client&quot;;
        import { Box, Button } from &quot;@chakra-ui/react&quot;;
        import { useMutation } from &quot;@tanstack/react-query&quot;;
        import { useAtom } from &quot;jotai&quot;;
        import { useRef } from &quot;react&quot;;
        
        type AudioStreamerProps = {
        talkId: string;
        };
        
        export const AudioStreamer = ({ talkId }: AudioStreamerProps) =&gt; {
        // 音声データの取得用の Ref
        const mediaRecorderRef = useRef&lt;MediaRecorder | null&gt;(null);
        const streamControllerRef =
        useRef&lt;ReadableStreamDefaultController&lt;Uint8Array&gt; | null&gt;(null);
        const [jwtToken] = useAtom(jwtTokenAtom);
        
        const { mutate, isPending } = useMutation({
        mutationFn: async (audioStream: ReadableStream&lt;Uint8Array&gt;) =&gt; {
        return await httpClient({ jwtToken })
        .post(`talks/${talkId}/stream`, {
        body: audioStream,
        timeout: false,
        })
        .text();
        },
        onSuccess: (data) =&gt; {
        console.log(data);
        },
        onError: (error) =&gt; {
        console.error(error);
        },
        });
        
        // 音声データを取得してサーバーにリクエストする
        const startRecording = async () =&gt; {
        try {
        // マイクへのアクセスをリクエスト
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        // MediaRecorderの作成
        const options = {
        mimeType: &quot;audio/webm; codecs=opus&quot;, // サポートされているmimeTypeを指定
        };
        const mediaRecorder = new MediaRecorder(stream, options);
        
        mediaRecorderRef.current = mediaRecorder;
        
        // ReadableStreamの作成
        const audioStream = new ReadableStream&lt;Uint8Array&gt;({
        start(controller) {
        // コントローラを保存して、後でデータをエンキューする
        streamControllerRef.current = controller;
        },
        });
        
        // dataavailableイベントのハンドリング
        mediaRecorder.addEventListener(&quot;dataavailable&quot;, async (event) =&gt; {
        if (event.data &amp;&amp; event.data.size &gt; 0) {
        // BlobをArrayBufferに変換
        const arrayBuffer = await event.data.arrayBuffer();
        // ArrayBufferをUint8Arrayに変換
        const chunk = new Uint8Array(arrayBuffer);
        // ReadableStreamにチャンクをエンキュー
        streamControllerRef.current?.enqueue(chunk);
        }
        });
        
        // stopイベントのハンドリング
        mediaRecorder.addEventListener(&quot;stop&quot;, () =&gt; {
        // ReadableStreamをクローズ
        streamControllerRef.current?.close();
        });
        
        // 録音開始（100msごとにデータを収集）
        mediaRecorder.start(100);
        
        // ReadableStreamをAPIに送信
        mutate(audioStream);
        } catch (error) {
        console.error(&quot;マイクへのアクセスエラー:&quot;, error);
        }
        };
        
        const stopRecording = () =&gt; {
        mediaRecorderRef.current?.stop();
        };
        
        return (
        &lt;Box&gt;
        &lt;Button colorScheme=&quot;red&quot; onClick={startRecording} isLoading={isPending}&gt;
        録音
        &lt;/Button&gt;
        &lt;Button
        colorScheme=&quot;blue&quot;
        onClick={stopRecording}
        isDisabled={!isPending}
        &gt;
        停止
        &lt;/Button&gt;
        &lt;/Box&gt;
        );
        };
        </code></pre>
        <p>バックエンドでは、ReadableStreamを受け取って <a href="https://github.com/ufal/whisper_streaming">whisper_streaming</a> のサーバー（これは別途立ち上げておく）に音声データを渡し、テキストデータを受け取る。</p>
        <pre><code class="language-ts">app.post(&quot;/:id/stream&quot;, permissionChecker(&quot;talks&quot;), async (c) =&gt; {
        // 音声データをReadableStreamで取得する
        const stream = c.req.raw.body as ReadableStream;
        const talkId = Number(c.req.param(&quot;id&quot;));
        const user = c.get(&quot;currentUser&quot;);
        
        if (stream) {
        // whisper streaming は サンプリングレートなどに指定があるため FFmpeg で変換する
        // これは Web Streams API でパイプできる
        const ffmpeg = new Deno.Command(&quot;ffmpeg&quot;, {
        args: [
        &quot;-i&quot;,
        &quot;pipe:0&quot;, // 標準入力からデータを受け取る
        &quot;-ar&quot;,
        &quot;16000&quot;, // サンプリングレートを16000Hzに設定
        &quot;-ac&quot;,
        &quot;1&quot;, // モノラルに設定
        &quot;-sample_fmt&quot;,
        &quot;s16&quot;, // サンプルフォーマットをs16に設定
        &quot;-f&quot;,
        &quot;wav&quot;, // 出力フォーマットをWAVに設定
        &quot;pipe:1&quot;, // 標準出力にデータを出力
        ],
        stdin: &quot;piped&quot;,
        stdout: &quot;piped&quot;,
        stderr: &quot;piped&quot;,
        });
        const ffmpegProcess = ffmpeg.spawn();
        
        stream.pipeTo(ffmpegProcess.stdin);
        
        const convertedAudioStream = ffmpegProcess.stdout;
        
        // WhipserStreamingServer は TCP サーバーなので Deno.connect で接続できる
        // これも Web Streams でパイプできる
        const whisper = await Deno.connect({
        hostname: Deno.env.get(&quot;WHISPER_HOST&quot;) || &quot;localhost&quot;,
        port: Number(Deno.env.get(&quot;WHISPER_PORT&quot;)) || 43001,
        });
        
        convertedAudioStream.pipeTo(whisper.writable);
        
        const reader = whisper.readable.getReader();
        const decoder = new TextDecoder(&quot;utf-8&quot;);
        let sentence = &quot;&quot;;
        const sentenceIdentifier = crypto.randomUUID();
        
        try {
        // Streams からテキストデータを受け取って、DBに保存したり通知したりする
        while (true) {
        const { done, value } = await reader.read();
        if (done) {
        break;
        }
        const text = decoder.decode(value);
        // 先頭に数字が入っているので削除
        const wordText = text.replace(/^[\d\s]+/, &quot;&quot;).replace(/\n/g, &quot;&quot;);
        
        if (wordText.length &gt; 0) {
        sentence += wordText;
        // 後述のGETリクエストでテキストデータを取得できるようにするためにNotifyする
        await notify(&quot;words_inserted&quot;, {
        id: crypto.randomUUID(),
        talkId,
        userId: user.id,
        words: wordText,
        sentenceIdentifier,
        });
        await modelWords.create({
        talkId,
        userId: user.id,
        words: wordText,
        sentenceIdentifier,
        });
        }
        }
        } catch (error) {
        if (error instanceof Deno.errors.Interrupted) {
        customLogger(&quot;POST クライアントが接続を閉じました。&quot;);
        }
        }
        
        return c.text(&quot;completed&quot;, 200);
        }
        
        return c.text(&quot;ストリームが存在しません&quot;, 400);
        });
        </code></pre>
        <h3>新しいテキストができた時にフロントで取得する部分</h3>
        <p>フロントではAIと話すページを開いたときにバックエンドに対してGETリクエストを出して、
        過去の会話履歴を取得するようにしている。
        このリクエストをStreamで繋いだままにしておいて、新しいデータが入れば取得するようにしておく</p>
        <pre><code class="language-ts">	const [words, setWords] = useState&lt;Word[]&gt;([]);
        
        useEffect(() =&gt; {
        const fetchStream = async () =&gt; {
        // 次のエンドポイントはReadableStreamを返す
        const response = await httpClient({ jwtToken }).get(
        `talks/${talkId}/stream`,
        );
        const stream = response.body;
        
        if (!stream) {
        console.error(&quot;このブラウザはストリーミングをサポートしていません。&quot;);
        return;
        }
        
        const reader = stream.getReader();
        const decoder = new TextDecoder(&quot;utf-8&quot;);
        try {
        while (true) {
        const { done, value } = await reader.read();
        if (done) {
        console.log(&quot;done!&quot;);
        break;
        }
        
        // 新しいデータを受け取ったら Words 配列にいれる
        // (なるべく連続するデータは同じフキダシに入れたいのでちょっとコードがごちゃごちゃしている)
        const chunk = decoder.decode(value, { stream: true });
        const json = JSON.parse(chunk);
        const lastWord = json[0];
        if (lastWord?.assistantId != null) {
        speak(lastWord.words);
        }
        setWords((prev) =&gt; {
        const newArray = [...json, ...prev];
        const result = newArray.reduce((acc, cur) =&gt; {
        const key = cur.sentenceIdentifier;
        acc[key] = {
        id: key,
        userId: cur.userId,
        talkId: cur.talkId,
        words: acc[key]
        ? `${cur.words}${acc[key].words}`.replace(/\n/g, &quot;&quot;)
        : cur.words.replace(/\n/g, &quot;&quot;),
        sentenceIdentifier: key,
        };
        
        return acc;
        }, {});
        return Object.values(result);
        });
        }
        } catch (error) {
        console.error(&quot;ストリームの読み取り中にエラーが発生しました:&quot;, error);
        }
        };
        
        fetchStream();
        }, [jwtToken, talkId]);
        
        // words 配列を表示する処理が続く
        </code></pre>
        <p>バックエンドでは PostgreSQL の <a href="https://www.postgresql.org/docs/current/sql-notify.html">Notify/Listen</a> 機能を使って
        Channel のようなことをする。
        これにより、新しいデータが追加されたらフロントエンドに送る。</p>
        <pre><code class="language-ts">app.get(&quot;/:id/stream&quot;, permissionChecker(&quot;talks&quot;), async (c) =&gt; {
        const talkId = Number(c.req.param(&quot;id&quot;));
        
        const words = await modelWords.findAllByTalkId(talkId);
        const wordsJson = JSON.stringify(words);
        
        // stream を返すのでクライアントが接続を切らない限りデータを渡し続けることができる。
        return streamText(c, async (s) =&gt; {
        await s.writeln(wordsJson);
        // words_insterted という channel にJSONテキストが入ってくるのでそれを監視する
        // WARN channel 名に talkId を入れたほうが他の会話のデータを誤って取得せずに済みそう
        await listen(&quot;listen words_inserted&quot;, async (msg) =&gt; {
        if (msg.channel !== &quot;words_inserted&quot;) {
        return;
        }
        
        const word = JSON.parse(msg.payload);
        await s.write(JSON.stringify([word]));
        });
        
        s.onAbort(() =&gt; {
        customLogger(&quot;GET クライアントが接続を閉じました。&quot;);
        });
        
        while (true) {
        await s.sleep(1000);
        }
        });
        });
        </code></pre>
        <p>listen と notify 関数の実装は次のような感じ</p>
        <pre><code class="language-ts">import { CamelCasePlugin, Kysely, PostgresDialect, sql } from &quot;kysely&quot;;
        import Pool from &quot;pg-pool&quot;;
        import type { DB } from &quot;./database-types.ts&quot;;
        import { clerk } from &quot;./libs/clerk.ts&quot;;
        
        export const pool = new Pool({
        connectionString:
        Deno.env.get(&quot;DENO_ENV&quot;) === &quot;test&quot;
        ? Deno.env.get(&quot;TEST_DB_URL&quot;)
        : Deno.env.get(&quot;DATABASE_URL&quot;),
        max: 20,
        idleTimeoutMillis: 30000,
        connectionTimeoutMillis: 2000,
        });
        
        const dialect = new PostgresDialect({
        pool,
        });
        
        export const db = new Kysely&lt;DB&gt;({
        dialect,
        plugins: [new CamelCasePlugin()],
        log: (log) =&gt; {
        if (log.level === &quot;query&quot;) {
        clerk.info(&quot;SQL&quot;, log.query.sql);
        }
        },
        });
        
        export async function notify(channel: string, obj: object) {
        return await sql`select pg_notify(${channel}, ${JSON.stringify(obj)})`.execute(
        db,
        );
        }
        
        export async function listen(
        listenChannel: string,
        callback: (msg: { channel: string; payload: string }) =&gt; void,
        ) {
        const pgClient = await pool.connect();
        pgClient.on(&quot;notification&quot;, callback);
        
        return await pgClient.query(listenChannel);
        }
        </code></pre>
        <h3>Local LLM へのリクエストとレスポンス</h3>
        <p>会話データができたので、これをもとにプロンプトを作成してローカルLLMにリクエストする。</p>
        <pre><code class="language-ts">import { Button } from &quot;@chakra-ui/react&quot;;
        
        export function TalkToAI({
        assistantMutate,
        assistantIsPending,
        }: { assistantMutate: () =&gt; void; assistantIsPending: boolean }) {
        return (
        &lt;Button
        colorScheme=&quot;blue&quot;
        onClick={() =&gt; assistantMutate()}
        isLoading={assistantIsPending}
        &gt;
        AIをよびだす
        &lt;/Button&gt;
        );
        }
        
        // assistantMutate の中身
        const { mutate: assistantMutate, isPending: assistantIsPending } =
        useMutation({
        mutationFn: async () =&gt;
        await httpClient({ jwtToken }).post(`talks/${talkId}/assistant_chat`, {
        timeout: false,
        }),
        onSuccess: () =&gt; {
        //
        console.log(&quot;ok&quot;);
        },
        onError: (error) =&gt; {
        console.error(error);
        },
        });
        </code></pre>
        <p>現状、AI呼び出しのトリガーはボタンにしてある。
        将来的にはユーザーが話し終わったら自動で処理するようにしたい。</p>
        <p>バックエンドでは <code>talks/${talkId}/assistant_chat</code> にリクエストがあると、次の処理を行う。</p>
        <ul>
        <li>次の情報からLLMのプロンプトを作成する
        <ul>
        <li>直近数回の人間とAIの会話データ</li>
        <li>AIの人格設定データ</li>
        </ul>
        </li>
        <li>ローカルLLMサーバー (Ollama を使用) にプロンプトを投げる</li>
        <li>レスポンスをStreamで受け取り、DBにNotify、保存</li>
        </ul>
        <pre><code class="language-ts">app.post(&quot;/:id/assistant_chat&quot;, permissionChecker(&quot;talks&quot;), async (c) =&gt; {
        const talkId = Number(c.req.param(&quot;id&quot;));
        const user = c.get(&quot;currentUser&quot;);
        const talk = await modelTalks.findById({
        talkId,
        userId: user.id,
        });
        
        if (!talk) {
        return c.json({ message: &quot;Talk not found&quot; }, 404);
        }
        
        // 直近数回の会話を取得
        const words = await modelWords.findLatestByTalkId(talkId);
        
        // 人間とAIの会話によって role を切り替えながらLLMのプロンプトを作成
        let messages = words
        .map((word) =&gt; ({
        role: word.userId == null ? &quot;assistant&quot; : &quot;user&quot;,
        content: `${word.words}`,
        }))
        .reverse();
        
        // AIの人格設定は system role で渡す
        messages = [
        ...messages,
        { role: &quot;system&quot;, content: talk.assistant.personality },
        ];
        
        // Ollama で動いているローカルLLMにリクエストする
        const response = await ky.post(`${Deno.env.get(&quot;OLLAMA_URL&quot;)}/api/chat`, {
        json: {
        model: talk.assistant.model,
        messages,
        stream: true,
        },
        });
        
        // ローカルLLMサーバーからのレスポンスをchannelに通知したり、保存したりする
        const reader = response.body?.getReader();
        const decoder = new TextDecoder(&quot;utf-8&quot;);
        const sentenceIdentifier = crypto.randomUUID();
        let text = &quot;&quot;;
        let textChank = &quot;&quot;;
        while (reader &amp;&amp; true) {
        const { done, value } = await reader.read();
        if (done) {
        break;
        }
        const jsonText = decoder.decode(value, { stream: true });
        const json = JSON.parse(jsonText);
        
        textChank += json.message.content;
        if (textChank.length &gt; 20) {
        await notify(&quot;words_inserted&quot;, {
        id: crypto.randomUUID(),
        talkId: talk.id,
        assistantId: talk.assistantId,
        words: textChank,
        sentenceIdentifier,
        });
        
        text += textChank;
        textChank = &quot;&quot;;
        }
        }
        
        if (textChank.length &gt; 0) {
        await notify(&quot;words_inserted&quot;, {
        id: crypto.randomUUID(),
        talkId: talk.id,
        assistantId: talk.assistantId,
        words: textChank,
        sentenceIdentifier,
        });
        
        text += textChank;
        textChank = &quot;&quot;;
        
        await modelWords.create({
        talkId,
        assistantId: talk.assistantId,
        words: text,
        sentenceIdentifier,
        });
        }
        
        return c.json({ msg: text });
        });
        </code></pre>
        <h3>AIからのレスポンステキストの読み上げ</h3>
        <p>ひとまずブラウザの機能で読み上げているだけ</p>
        <pre><code class="language-ts">function speak(text: string) {
        // SpeechSynthesisUtteranceのインスタンスを作成
        const utterance = new SpeechSynthesisUtterance();
        utterance.text = text;
        utterance.lang = &quot;ja-JP&quot;;
        // 音声を再生
        window.speechSynthesis.speak(utterance);
        }
        </code></pre>
        <p>新しいテキストを取得した際に、AIからの発言であれば上記の関数を使って読み上げる。</p>
        <h2>今後の展望</h2>
        <p>テキスト読み上げが地味なので <a href="https://github.com/VOICEVOX/voicevox_engine">VOICEVOX</a> などをつかって音声データをサーバーで作成し、
        フロントに送るようにしたい。
        これもStreamを利用してリアルタイムにやりたいので、そんな感じの仕組みを作成中。</p>
        <p>すべてのソースコードの公開は全体が完成したらします。</p>
        ]]>
      </content:encoded>
      <pubDate>Sat, 14 Dec 2024 07:05:34 GMT</pubDate>
    </item>
    <item>
      <title>Clojure Family が色々ある話</title>
      <link>https://www.kbaba1001.com/posts/202412030751_clojure-family/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202412030751_clojure-family/</guid>
      <content:encoded>
        <![CDATA[<p>Clojure といえば JVM 上で動く Lisp のように紹介されることが多く、
        私もそういう言い方をすることも多いのだがこの言い方は正しくない。
        なぜなら JVM 以外で動く Clojure (あるいは Clojure っぽい言語も含む) が多々存在しているからだ。</p>
        <p>今日は Clojure Family とも言うべきこれらの方言について紹介する。</p>
        <h2>Clojure (JVMで動くやつ)</h2>
        <p>まずは一番良く使われている JVM 上で動く Clojure 。
        特筆されない場合 &quot;Clojure&quot; といえばこれのこと。</p>
        <ul>
        <li>Java の機能やエコシステムを活用したい場合はとてもよい</li>
        <li>とりあえず Clojure を使いたい場合はこれがおすすめ</li>
        </ul>
        <h2>ClojureScript (Alt JS の一種)</h2>
        <p>ビルドすると JavaScript になる Clojure 。
        おそらく JVM 版の次によく使われている。
        JVM 版と同じところが開発しているという安心感がある。</p>
        <p>ただ、ビルドツールが色々とあって、</p>
        <ul>
        <li><a href="https://clojurescript.org/guides/quick-start">deps.ednを使う方法</a></li>
        <li><a href="https://figwheel.org/">Figwheel</a></li>
        <li><a href="https://github.com/thheller/shadow-cljs">Shadow-cljs</a></li>
        </ul>
        <p>などのやり方がある。</p>
        <p>「deps.edn を使う方法」は公式サイトに乗っているやり方だが、これは npm ライブラリを素直に使えないというデメリットが有り、
        そのへんを解決するために後者の 2 つがある。</p>
        <p>Shadow-cljs が一番後発なので、今から新しく何かを作りたいなら、これがおすすめ。
        （あるいは後述の squint や cherry を使う）</p>
        <h2>ClojureCLR</h2>
        <p>こちらも Clojure 本家が作成しているもので、 ビルドすると Microsoft’s .Net Framework 環境で動く Clojure 。
        つまり C# で書かれた Clojure 実装。</p>
        <p>私は使ったことがなく、詳しくないので紹介する程度に留める。
        ゲームとかWindowsサーバーでClojureを使いたい人にはいいのかもしれない。</p>
        <h2>Babashka</h2>
        <p><a href="https://babashka.org/">Babashka</a> は GraalVM を用いて Clojure を native binary にビルドできるもの。</p>
        <p>JVM 版の Clojure を使うとどうしても実行時の起動に時間が掛かるが、 Babashka であればすぐに動くので
        スクリプトを Clojure で書きたい場合などに便利。</p>
        <p><a href="https://github.com/borkdude">Michiel Borkent</a> 氏の作品。彼は Babashka を始め後述の様々なツールを作っているすごい人。</p>
        <h2>Squint</h2>
        <p><a href="https://github.com/squint-cljs/squint">squint</a> は ClojureScript のコンパイラなのだが、 JavaScript の Built-in Data structures のみ使用しているため、いくつかの点で本来の ClojureScript とは異なる。</p>
        <ul>
        <li>ClojureScript では <code>[]</code> や <code>{}</code> は JavaScript のオブジェクトではなく immutable な ClojureScript ようにカスタムされたオブジェクトを返すが、 Squint では JavaScript の build-in の <code>Array</code> や <code>Object</code> を返す。</li>
        <li>Async/Await のサポート (ClojureScript では core.async などを使う必要があったが Squint では Promise が素直に使える)</li>
        <li>ClojureScript 用に開発されたライブラリなどがうまく動かない場合があるので、JS/TS用のライブラリを使うほうが無難</li>
        <li><a href="https://github.com/brandonstubbs/vite-plugin-squint">vite-plugin-squint</a> などを使うと Squint -&gt; JSX -&gt; JS の変換が楽</li>
        </ul>
        <p>Squint はないよりも気軽に CLJS （っぽい言語）が使えるのが魅力。
        私としてはかなり期待している。</p>
        <h2>Cherry</h2>
        <p><a href="https://github.com/squint-cljs/cherry">Cherry</a> は Squint よりもともとの ClojureScript への互換性を高めたもの。
        ClojureScript のライブラリを活用したい場合はこちらのほうが良さそう。</p>
        <h2>Jank</h2>
        <p><a href="https://jank-lang.org/">Jank</a> は Clojure を LLVM + JIT コンパイラで動くようにしたもの。
        C++との親和性が高いらしく、C/C++ っぽい領域のところを Clojure で書きたい場合には良さそう。
        どのくらいの事ができるのかをまだ私は把握しきれていないけど、将来性はあるように思うので期待。</p>
        <h2>その他</h2>
        <p>私は使ったことないけど他のClojure方言を紹介</p>
        <ul>
        <li><a href="https://github.com/Tensegritics/ClojureDart">ClojureDart</a></li>
        <li><a href="https://github.com/clojerl/clojerl">ClojureL</a>
        <ul>
        <li>Erlang 実装</li>
        </ul>
        </li>
        <li><a href="https://github.com/kanaka/mal">mal</a>
        <ul>
        <li>Clojure っぽい言語を実装することで言語実装について学ぶプロジェクト</li>
        </ul>
        </li>
        </ul>
        <h2>感想</h2>
        <p>Lisp は方言がたくさんある言語だけど、最近はもうClojure方言と呼ぶべき分野ができていて、
        やっぱりClojureの人気はすごいなぁと思ったりしました。
        Scheme方言なんかも結構たくさんあるみたいで調べてみると面白かったです。</p>
        ]]>
      </content:encoded>
      <pubDate>Tue, 03 Dec 2024 07:51:05 GMT</pubDate>
    </item>
    <item>
      <title>渋谷でもくもく会に参加した</title>
      <link>https://www.kbaba1001.com/posts/202411030733_attended-shibuya-mokumoku/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202411030733_attended-shibuya-mokumoku/</guid>
      <content:encoded>
        <![CDATA[<p><img src="https://www.kbaba1001.com/img/posts/202411030733/mokumoku.jpg" alt="渋谷でもくもく会"></p>
        <p><a href="https://connpass.com/event/334713/">渋谷でもくもく会</a> に参加してきた。</p>
        <p>こういうイベントに参加するのは久しぶりで楽しかった。</p>
        <h3>会の雰囲気</h3>
        <p>シェアオフィスでの開催だったので静かな空間で良かった。
        参加者も１０人くらいで適度におしゃべりしたりするのにちょうどいい感じ。</p>
        <p>もくもく会だが、作業したり喋ったりゆるい雰囲気で良かった。
        （ずっと黙っている会もあったりするが、自分好みではない）</p>
        <p>他の参加者は若手と中堅のエンジニアの方が半々くらいで、
        適度に会話が盛り上がって楽しかった。
        意外と女性の参加者も多かった。</p>
        <p>私は最近静岡に引きこもっているので、Tech系の話をするのは久々で
        自分がこういうおしゃべりに飢えていたことに気づいた。</p>
        <p>若手エンジニアの方たちの話は自分にとっては新鮮なところもあって、
        転職の話とかどのように技術を学んでいくかとか、話題が若くて良かった。</p>
        <h3>やっていたこと</h3>
        <p>最近 ChatGPT に AI と音声で会話できる機能がついたのだが、それと同じようなものを
        ローカルLLMを使って実現したい。次の流れで実現できると思っている。</p>
        <ul>
        <li>ユーザーの音声のテキスト化
        <ul>
        <li>ユーザーの音声をブラウザで取得</li>
        <li>音声データをStreamでサーバーにおくる</li>
        <li>サーバーでは音声データをWhisperで文字に変換する (ここもStream処理)</li>
        <li>文字データをフロント側にStreamで返却しつつ、DBにも保存する</li>
        </ul>
        </li>
        <li>テキストをローカルLLMにわたして返答をつくる
        <ul>
        <li>１００文字くらいの短い文章を作るように命令しておく</li>
        <li>インプットはStreamではなくまとめてテキストデータを入れる</li>
        <li>アウトプットをStream で受け取る</li>
        </ul>
        </li>
        <li>LLMの返答を音声データにする
        <ul>
        <li>LLMのアウトプットを Stream で受け取り、それを <a href="https://github.com/KoljaB/RealtimeTTS">RealtimeTTS</a> などを用いて Stream で音声データにする</li>
        <li>サーバーからフロントに音声データと文字データを Stream で送る</li>
        <li>フロントではサーバーからのレスポンスを Stream で受け取りつつ、音声を再生し、文字データを画面に表示する</li>
        </ul>
        </li>
        </ul>
        <p>もくもく会では、ブラウザ上で音声データを取得して ReadableStream でサーバーに送り、
        サーバー側でファイル化するという処理を作ることができた。</p>
        <p>実際には受け取ったバイナリをファイルにするんじゃなくて、そのまま <a href="https://github.com/ufal/whisper_streaming/blob/main/whisper_online_server.py">whisper_online_server.py</a> に渡してテキスト化したい。</p>
        <h3>結果</h3>
        <p>会場ではかなり集中して作業できてきちんとした進捗が出せてよかった。</p>
        <p>12:00 - 18:30 （わたしは 17:30 で帰ったけど）という長時間の会だったので、
        なかなか普段ここまでまとまった時間は取れないので、それだけでもありがたかった。</p>
        <h3>蛇足: わからないことをAIに聞くことに慣れた</h3>
        <p>会とは関係ないけど WebStream API をつかったコーディングは初めてで
        MDNのサンプルコードだけだとしんどいなぁと思っていたところ、
        ChatGPTにサンプルコードを提示させるとかなりいいコードがでてきて、
        なんかもうこれでいいじゃんとなった。
        こういう規格に沿ったものをつくるのはAIのほうが得意そうだ。</p>
        <p>バックエンドも Deno にしているので Web 標準の機能が使えてスッキリするが、
        これも資料が少ないので ChatGPT に聞いたほうが何かと早い。。。</p>
        <p>ChatGPTの作ったコードをとりあえず動かしてみて、問題があったらドキュメントを参考に修正するという感じ。</p>
        <p>すごい時代になったなぁ。。。</p>
        ]]>
      </content:encoded>
      <pubDate>Sun, 03 Nov 2024 07:33:24 GMT</pubDate>
    </item>
    <item>
      <title>ここ数年について</title>
      <link>https://www.kbaba1001.com/posts/202410291201_recently-a-few-years/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202410291201_recently-a-few-years/</guid>
      <content:encoded>
        <![CDATA[<p>最近何やってるの？、をざっくりまとめる。</p>
        <h3>プログラミング、絵、その他</h3>
        <p>以前にもまして家にこもりがちで、相変わらずプログラムを書いている。
        絵もたまに書いている。</p>
        <p>なんか自分の中の行動としてこの２つで固めていこうという感じがしている。</p>
        <p>プログラミングは以前にもまして他の人に説明しづらくなってきた。
        Clojureも時々は書いていて、TypeScriptも渋々とはいえ使い慣れてしまったほどには書いている。
        TSに関してはGoよりは書きやすく、仕事で使うならこれでいいかなぁーという感じがある。
        一人で書くコードに関してはなるべくClojureを使いたいが、それも結構面倒くさくて結局TSで書いていることも多い。</p>
        <p>プログラミング以外のIT系のこととしては自宅サーバーを始めたり、ローカルLLMで遊んだりしている。
        自宅サーバーの話はこのブログでもたまに書いているけど、そろそろ docker compose で色々やるのが限界なので
        k8s でも導入しようかと思っている。
        年末年始に少し自宅サーバーのパーティションなども整理したいと思いつつ、どうなることやら。</p>
        <p>AIに関してはわくわく感より恐ろしさのほうが強くていまいち熱中しきれないでいる。
        将来的にプログラムを手で書くような時代は終わってしまうのかもしれないと思うと淋しい。
        ChatGPTなども使っているがやはりローカルで動かしたいのでローカルLLMの研究をすることが多い。</p>
        <h3>辞めることを覚えようとしている</h3>
        <p>気がつけば３５歳になっていた。気持ち的には２０台後半くらいから何も変わってないのだが、
        体は明らかに代謝・体力など落ちていて、以前ほど集中力も続かなくなった。</p>
        <p>何より、眠い。</p>
        <p>夜起きていられない。19時ごろには眠っていることが多い。
        で、朝は3, 4時頃起きている。</p>
        <p>そんなわけで、なるべくやりたいことを減らすように努力しようと家族会議で決まった。
        やりたいことを絞って、なるべくゆっくり暮らすように心がけたい。</p>
        <p>ちょっと今まで忙しくしすぎた。</p>
        <h3>生活のこと</h3>
        <h4>近所付き合い</h4>
        <p>静岡県三島市に引っ越して早くも３，４年くらい経っている。
        生活は落ち着いてきた。引っ越し当初はコロナ禍で近所付き合いもなかったが、
        最近は町内会の組長をやっている都合もあり、少しは近所の人とも関わるようになった。
        具体的にはお祭りでかき氷を売ったりとか。それなりに楽しくやっている。</p>
        <h4>外食と酒</h4>
        <p>東京で暮らしていた頃に比べると、明らかに外食が減っている。
        とくに外で酒を飲むと代行代が結構かかるので、もっぱら宅飲みになった。
        その酒も以前よりはかなり減っていて、月に２，３回程度。
        一度飲むと少し飲みすぎるきらいがあるけど、飲まないときは数ヶ月飲まないこともある。</p>
        <h4>SNS、友人関係</h4>
        <p>去年くらいに X (Twitter) や Instagram などあらかたアカウントを消してしまって、Facebookもほぼ見なくなった。
        なんかインターネットに疲れた。SNSをやる楽しさより、知らない人の怒りみたいなものに触れることが増えてなんか嫌になってしまった。
        炎上みたいなのも別に自分の生活には関係ないことが多いし、ニュースも陰鬱な話題が多いし。</p>
        <p>代わりにやっているインターネットと言えば、 Discord でエンジニアとか絵描きさんとかと話をさせてもらっている。
        Discord は変に拡散されたりしない安心感がある（とはいえ公共の場ではあるが）。</p>
        <p>あとは zenn.dev の新しい記事を時々見たりしている程度だが、新しい情報のキャッチアップは思ったより困ってない気がする。</p>
        <p>友人関係は２０代の知り合いは結婚したり引っ越したりでみな生活が変わってしまった感じがしていて、
        自分も人のことは言えず三島に引きこもっているわけで、時の流れを感じることが多く、やや淋しい。</p>
        <p>特にTech系の話題を気楽にできていた２０代の頃を思い起こすと、今はなんだかなぁという感じもする。
        自分の興味のあるTechの話がマイナーになりすぎたのもあるし、勉強会とか行かなくなったのもあるし。</p>
        <p>東京を離れて三島に来たことは本当に良かったと思っているが、
        コミュニティとの関わり方みたいなのはもう少しやり方を覚えたいなぁと思ったりしている。</p>
        <h3>古い人間関係が復活したり</h3>
        <p>一方で、この5年間で実家には２度帰った。一生帰るつもりがなかったことを考えればすごいことだと思うが、
        やはり実家の人間関係は自分にはしんどくてもう十分かなぁという気持ちもある。
        兄とはたまにLINEしている。２０代の頃は考えられなかったことなので成長だと思うことにする。</p>
        <p>しばらく前に、高校の時の知り合いにもあった。飲み会を開いてくれて楽しかった。
        同じIT業界にいるせいか、世間が狭いのか、全く関係ないところで知り合った共通の知人が数名いて不思議だった。</p>
        <p>シェアハウス仲間にも久々に会ったりした。
        東京にいる人にはやはり会いやすいけど、地方の人には合う機会は減るもののつながりはなんとか続いている。
        地方で会えるとなんか楽しい。三島にも来てもらえたらやっぱり嬉しいし。</p>
        ]]>
      </content:encoded>
      <pubDate>Tue, 29 Oct 2024 12:01:11 GMT</pubDate>
    </item>
    <item>
      <title>近々やりたいこと2024年10月</title>
      <link>https://www.kbaba1001.com/posts/202410200712_what-I-will-do-from-2024-10/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202410200712_what-I-will-do-from-2024-10/</guid>
      <content:encoded>
        <![CDATA[<p>近々やりたいこと</p>
        <ul>
        <li>ClojureScript (Squint) 関係の動画
        <ul>
        <li>プログラミングしながら雑談するような、プログラミング Vlog 動画を作りたい</li>
        </ul>
        </li>
        <li>Ollama か llama-cpp-python をベースにしてローカル AI と日本語で音声通話できる仕組みを作りたい
        <ul>
        <li>喋った言葉を whisper でテキスト化してローカルllm に認識させて、その結果を VOICEVOX で読み上げさせる</li>
        <li>Ollama は JS 対応されているのでうまいことクライアント作れば良さそう
        <ul>
        <li>とりあえず Web ベースのクライアントで良い</li>
        <li>コードも理解させるなら VS Code プラグインが理想かもしれない</li>
        </ul>
        </li>
        <li>以前から作っているローカルAI: Poppins システムの発展型</li>
        </ul>
        </li>
        <li>Supabase (Self-host) + Deno Fresh + Squint でシステム構築
        <ul>
        <li>以前から作っている FAM システムの作り直し</li>
        <li>ロードバランサ (Kong か Caddy あたり) をうまく使って拡張できるようにしたい</li>
        <li>今まで特定のサービスに依存しないシステム開発を心がけてきたけど、次の理由でSupabase依存することにした
        <ul>
        <li>PGroonga が動くクラウドシステムは Supabase のみ</li>
        <li>Supabase が self-host できるので必ずしもクラウド依存ではない</li>
        <li>Supabase 使うほうが認証とかストレージとか楽そう</li>
        </ul>
        </li>
        <li>Deno Fresh について
        <ul>
        <li>React より Preact のほうが好み</li>
        <li>Preact 前提なら vite で頑張るより Fresh 使うほうが楽かも</li>
        <li>サーバーサイドが Supabase 前提で簡略化出来るなら backend と frontend を分けなくても良さそう</li>
        </ul>
        </li>
        <li>Squint について
        <ul>
        <li>Squint で js, jsx を出力してそれを Deno Fresh で動かせれば理想</li>
        <li>もちろん Squint 使わないほうが一般的だし楽だけども、やはり Clojure を書きたい</li>
        </ul>
        </li>
        </ul>
        </li>
        <li>技術書典 (11/3) 参加予定
        <ul>
        <li>自宅サーバー本が出ます</li>
        <li>ローカル AI 本も出るかも？間に合えば…</li>
        </ul>
        </li>
        <li>ISUCON
        <ul>
        <li>参加申込済みだけどいまいち練習できていない。やらねば。。。</li>
        </ul>
        </li>
        <li>Rust の勉強
        <ul>
        <li>ISUCON 終了後に着手できそう</li>
        <li>本を3冊買ってあるので勉強したい</li>
        <li>特に WASM とか Web 対応とかが気になる</li>
        </ul>
        </li>
        <li>自宅サーバーに関する動画作成
        <ul>
        <li>自宅サーバー + NextCloud の話をもう少ししたい</li>
        <li>自宅サーバー + Local LLM の話もしたい</li>
        </ul>
        </li>
        </ul>
        <hr>
        <p>上記の箇条書きを ChatGPT 4o with canvas で文章化しました。↓</p>
        <hr>
        <p>やりたいことがたくさんあってワクワクしているので、近々取り組みたいプロジェクトについてまとめてみました。</p>
        <h3>ClojureScript (Squint) 関連の動画</h3>
        <p>ClojureScriptの一環として、特に&quot;Squint&quot;に関係するプログラミングのVlog動画を作りたいと思っています。プログラミングをしながら雑談をするような形式で、リラックスした雰囲気の動画になる予定です。技術的な内容と日常的な思考を共有することで、視聴者の皆さんと同じ熱意を共有できると嬉しいです。</p>
        <h3>ローカルAIと日本語で音声通話する仕組み</h3>
        <p>次に取り組みたいのが、Ollamaやllama-cpp-pythonをベースにして、ローカルAIと日本語で音声通話できる仕組みの開発です。これは、話した言葉をWhisperでテキスト化し、その内容をローカルのLLM（大規模言語モデル）に理解させ、その結果をVOICEVOXで読み上げる、という流れを想定しています。特にOllamaはJavaScript対応されているので、Webベースのクライアントを作ってテストしてみたいと思っています。最終的にはVS Codeプラグインとして、コードも理解する形に進化させるのが理想です。このアイデアは以前から作っているローカルAI、&quot;Poppinsシステム&quot;の発展型と考えています。</p>
        <h3>Supabase + Deno Fresh + Squint でシステム構築</h3>
        <p>次に、Supabase（Self-host）とDeno Fresh、そしてSquintを使って新たなシステム構築に取り組もうと思っています。このプロジェクトは、以前から作っているFAMシステムの改良版です。ロードバランサ（KongやCaddyなど）を使って、より拡張性のあるシステムにすることが目標です。</p>
        <p>これまで私は、特定のサービスに依存しないシステム開発を心がけてきましたが、以下の理由でSupabaseを選びました。</p>
        <ul>
        <li>PGroongaが動作するクラウドシステムはSupabaseのみ</li>
        <li>Supabaseはセルフホスト可能で、必ずしもクラウドに依存しない</li>
        <li>認証やストレージなどが簡単に利用できる</li>
        </ul>
        <p>Deno Freshを使う理由としては、Reactよりも軽量なPreactが好みであり、Preact前提ならFreshのほうがシンプルに開発できそうだからです。また、バックエンドとフロントエンドを分ける必要もないため、全体の開発が楽になると考えています。</p>
        <p>Squintについては、JavaScriptやJSXを生成してDeno Freshで動かすことを目指しています。もちろんSquintを使わないほうが一般的ではありますが、それでもClojureを書く楽しさを手放したくない気持ちがあります。</p>
        <h3>技術書典への参加</h3>
        <p>11月3日に開催される技術書典に参加する予定です。そこで、自宅サーバーに関する本を出す予定です。さらに、ローカルAIに関する本も間に合えば出したいと考えています。</p>
        <h3>ISUCONの参加</h3>
        <p>ISUCONに申し込んでいますが、まだあまり練習できていません。本番に向けてもう少し頑張って準備しなければと感じています。</p>
        <h3>Rustの勉強</h3>
        <p>ISUCONが終わったら、Rustの勉強にも取り組みたいと思っています。すでに3冊の本を購入しているので、これらを活用して特にWASMやWeb関連の技術に注目しながら学んでいく予定です。</p>
        <h3>自宅サーバーに関する動画作成</h3>
        <p>最後に、自宅サーバーに関する動画も作成したいと考えています。特に、自宅サーバーとNextCloudの設定や、自宅サーバーとローカルLLMの連携についてもう少し掘り下げて共有したいです。</p>
        <p>こうしてみると、たくさんのプロジェクトがありますが、どれも非常に楽しみで取り組むのが待ち遠しいです。少しずつ進めて、ブログや動画で進捗を共有していければと思っています。</p>
        <p>《kbaba1001|/img/horse.jpg|普通に読める文章になっていて恐ろしい...》</p>
        <hr>
        <p>ちなみに、同じプロンプトで llama3-elyza-jp-8b を実行した結果は次:</p>
        <hr>
        <p>タイトル: 近々やりたいことのまとめ - プログラミングとローカルAIの活用 -</p>
        <p>近いうちに取り組みたいプロジェクトや活動について、箇条書きで整理してみました。以下はその内容です。</p>
        <p>先日、技術書典11/3に参加し、自宅サーバー本を出します。同時に、ローカルAI本も出る予定です。他にも、ISUCONやRustの勉強、ClojureScriptやOllamaを活用したローカルAIと音声通話、SupabaseやDeno Freshを使用したシステム構築など多くのプロジェクトが控えています。</p>
        <p>以下は、各プロジェクトの詳細です。</p>
        <ol>
        <li>
        <p>ClojureScript関係の動画:
        プログラミングしながら雑談するVlog動画を作りたい。Ollamaやllama-cpp-pythonを使用し、ローカルAIと日本語で音声通話できる仕組みを構築します。</p>
        </li>
        <li>
        <p>Ollamaやllama-cpp-pythonのクライアント作成:
        Webベースのクライアントを作る予定です。VS Codeプラグインが理想かもしれません。</p>
        </li>
        <li>
        <p>Supabase、Deno Fresh、Squintでのシステム構築:
        以前から作っているFAM システムをSupabaseで再構築します。ロードバランサを使って拡張できるようにし、認証やストレージを楽に設定したいです。</p>
        </li>
        <li>
        <p>Deno Freshについて:
        Preactを使用してFreshでアプリケーションを作成する予定です。サーバー側の設定が簡略化されるならば、backendとfrontendを分ける必要はなさそうです。</p>
        </li>
        <li>
        <p>Squintについて:
        Squintでjs,jsxを出力し、Deno Freshで動かすことが理想です。もちろん一般的にはClojureScriptを使わないほうが楽ですが、書きたいから使います。</p>
        </li>
        <li>
        <p>技術書典11/3の参加と自宅サーバー本の出版:
        自宅サーバー本を出します。ローカルAI本も出る予定です。</p>
        </li>
        <li>
        <p>ISUCONの参加申し込みとRustの勉強:
        ISUCONに参加申込済みですが、練習できていません。やらねばです。Rustの勉強は、ISUCON終了後から始める予定です。</p>
        </li>
        <li>
        <p>自宅サーバーに関する動画作成:
        自宅サーバーとNextCloudやローカルLLMについての話をまとめたいです。</p>
        </li>
        </ol>
        <p>以上が近々やりたいことの内容です。</p>
        <p>《kbaba1001|/img/horse.jpg|要約してくれた感じだね》</p>
        <p>やはり llama2 系に比べれば圧倒的に進歩しているけど、 ChatGPT 4o にはもちろん及ばず。
        でもこれくらい動けばなにかできそうではある。</p>
        ]]>
      </content:encoded>
      <pubDate>Sun, 20 Oct 2024 07:12:38 GMT</pubDate>
    </item>
    <item>
      <title>Squint で切り開く ClojureScript の新しい可能性</title>
      <link>https://www.kbaba1001.com/posts/202410130849_opening-up-new-possibilities-for-clojure-script-with-squint/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202410130849_opening-up-new-possibilities-for-clojure-script-with-squint/</guid>
      <content:encoded>
        <![CDATA[<p>少し前から <a href="https://github.com/squint-cljs/squint">Squint</a> という軽量な ClojureScript (CLJS) のコンパイラがあります。
        最近これで遊び始めたのでざっくり紹介したいです。</p>
        <p>《kbaba1001|/img/horse.jpg|TypeScriptと同程度の気楽さでClojureScriptを使いたい》</p>
        <p>簡単に言えばこれを叶えるための選択肢としての Squint です。</p>
        <h3>そもそも今までの CLJS と何が違うのか</h3>
        <p>今までの CLJS はこんな感じでした。</p>
        <ul>
        <li>Java の Clojure との高い互換性を重視</li>
        <li>CLJS の実行に Java が必要 (<a href="https://github.com/thheller/shadow-cljs">shadow-cljs</a>はだいぶ頑張ってこれをなくそうとしていたけど…)</li>
        <li>ビルドのアウトプットファイルが大きい
        <ul>
        <li>JS のデータ構造をそのまま使うわけではないので標準で色々入っている分重い</li>
        </ul>
        </li>
        <li>JS のデータ構造を使う場合には <code>#js</code> や <code>clj-&gt;js</code> などを使って変換する必要があった
        <ul>
        <li>これで困ることはあんまりなかったけど、初心者には分かりづらいポイントかも</li>
        </ul>
        </li>
        <li>Promise の扱いが微妙
        <ul>
        <li><a href="https://github.com/clojure/core.async">core.async</a> で十分なことは多いけど、 JS の Promise を使いたいケースも結構ある</li>
        <li>core.async の関数の戻り値が Promise ではないのがたまに辛い</li>
        </ul>
        </li>
        <li>package.json とかに書いたらいい感じにやってほしいけど、なんかごちゃごちゃする
        <ul>
        <li>shadow-cljs はだいぶ良かった</li>
        </ul>
        </li>
        <li>cljs 対応済みの clojure ライブラリが使える</li>
        </ul>
        <p>何度も言いますが Shadow-cljs は最高です。 npm で動くし、今までの ClojureScript のライブラリも使えます。
        難点を上げるとすれば、ビルドが遅くて重く、なんとなく気楽さに欠けることでしょうか。</p>
        <p>Vite などの JS 文化のビルドライブラリを使いたいというのが正直なところです。</p>
        <p>そこで、 Squint 。</p>
        <p>Squint は今までの Clojure(Script) との互換性を捨てる代わりに、</p>
        <ul>
        <li>JS のデータをそのまま使うことによるアウトプットの軽量化</li>
        <li>Promise, Async/Await のサポート</li>
        <li>JSX 対応</li>
        </ul>
        <p>などが入り、 vite などと組み合わせて使うことも出来るようになりました。</p>
        <p>なので</p>
        <p>《kbaba1001|/img/horse.jpg|今までの cljs は不要だけど、 js の資産を活用して cljs で開発したい》</p>
        <p>のような考えの人には向いていると思います。
        詳細は <a href="https://github.com/squint-cljs/squint?tab=readme-ov-file#differences-with-clojurescript">このへん</a> を読んでください。
        今までの CLJS との互換性を重視した <a href="https://github.com/squint-cljs/cherry">cherry</a> というプロジェクトもあります。</p>
        <h3>まずはサンプルコード</h3>
        <p><a href="https://github.com/neumann-tokyo/vite-preact-squint">vite-preact-squint</a></p>
        <p>vite, preact, squint で土台を作ってみた。まだ途中だけどとりあえず squint でビルドした jsx を vite で動かすところまではできた。</p>
        <p>vite squit plugin みたいなやつがあればよいのだが、そこまではまだできていないようで、
        <code>squint watch</code> で js/jsx ファイルを作ってそれを <code>vite</code> に食べさせるという動き。</p>
        <p>そうすると２つのプロセスを同時に起動する必要があり、やや面倒なので <a href="https://github.com/chrismytton/shoreman">Shoreman</a> という <a href="https://github.com/ddollar/foreman">Foreman</a> を shell に移植したやつをリポジトリ内に入れて使うことにした。
        (この辺はもう少しシンプルにできそうな気がするけど)</p>
        <p><a href="https://github.com/brandonstubbs/vite-plugin-squint">vite-plugin-squint</a> を作っている人もいたので、後で試す。</p>
        <h3>cljs で malli だけ使いたい</h3>
        <p><a href="https://github.com/metosin/malli">malli</a> は cljs で動的に typecheck が出来るライブラリで、
        <a href="https://github.com/clojure/spec.alpha">clojure/spec.alpha</a> の代わりによく使われている。</p>
        <p>malli の良いところはデータ構造で spec を定義できて、かつ、 Validation などでも使えることだ。</p>
        <p>TypeScriptのような型システムは別にいらないのだが、単に関数の引数として何を期待しているのかを
        明白にしておきたいときは結構あって、 Malli はそういうときにちょうどいい。</p>
        <h4>Squint で Malli は動かない。ではどうするか？</h4>
        <p>先ほど互換性の話をした通り Squint では普通の CLJS ライブラリは動かないので Malli も動かない。</p>
        <p>ではどうするか？ JS のライブラリで似たようなものを探すしかない。</p>
        <p>「引数に何を期待しているかを明記する」という目的であれば <a href="https://www.npmjs.com/package/prop-types">PropTypes</a> をまず思いついた。</p>
        <p>しかし、案の定 PropTypes は放置されていて、世の中的にはそういうのは「 TypeScript を使え」の一点張りになってしまっていた。
        PropTypes的なライブラリで代替品も見つからない。</p>
        <p>《kbaba1001|/img/horse.jpg|発想を変えよう》</p>
        <h4>Validation ライブラリを Spec 代わりに使う</h4>
        <p>Clojure には <code>pre</code>、 <code>post</code> という機能がある。
        関数の事前条件(<code>pre</code>)または事後条件(<code>post</code>)を設定して、条件を満たしていなければ例外を出すというものだ。</p>
        <p>Malli にせよ clojure/spec.alpha にせよ、静的な型チェックとは異なり、
        動的な型チェックというのは何かしらの方法で実行して確認する必要がある。</p>
        <p>方針としてはこうだ。</p>
        <ul>
        <li><code>pre</code> で validation チェックライブラリ ( <a href="https://zod.dev/">zod</a> や <a href="https://valibot.dev/">valibot</a> など ) を実行して引数のチェックをする</li>
        <li>この機構は本番モード(<code>NODE_ENV=production</code>)では無視する（必ずパスする）ようにする</li>
        <li>テストを活用する</li>
        </ul>
        <p>このやり方なら JS の新しいライブラリを使って Malli が行っているような動的な型チェックが出来る。</p>
        ]]>
      </content:encoded>
      <pubDate>Sun, 13 Oct 2024 08:49:58 GMT</pubDate>
    </item>
    <item>
      <title>CADをやり始めた</title>
      <link>https://www.kbaba1001.com/posts/202409280830_i-challenge-a-cad/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202409280830_i-challenge-a-cad/</guid>
      <content:encoded>
        <![CDATA[<p><a href="https://cadiy3d.com/wp/"><img src="https://www.kbaba1001.com/img/posts/202409280830/caDIY3D.png" alt="caDIY3D"></a></p>
        <p><a href="https://cadiy3d.com/wp/">caDIY3D</a> というソフトで CAD を始めてみることにした。</p>
        <p>自分でも意外なことに今まで CAD をやったことがない。
        DIY の設計図は斜視図で紙や iPad で書くことでなんとかしてきていた。</p>
        <p>だが、いい加減 CAD を覚えようと思った。
        世の中には CAD のソフトが有料・無料あわせてたくさんあるのだが、
        caDIY3D が次の点で良さそうだと思って試している。</p>
        <ul>
        <li>価格が安い (買い切りで1万円くらい)</li>
        <li>DIY に特化した機能がある
        <ul>
        <li>ホームセンターで売っているような材料で設計できる</li>
        </ul>
        </li>
        <li>設計を元に木取り図を自動生成してくれる
        <ul>
        <li>木取り図とは、作ろうとしているものに対してどの材料をどのくらい買えばいいかという図</li>
        <li>基本的にホームセンターで売っているものは 3～8フィートくらいなので、その範囲で材を切る必要がある</li>
        </ul>
        </li>
        <li>機能が限られている分、直感的な 3D の UI で設計可能</li>
        </ul>
        <p>たぶん 3D プリンターなどを使うのであれば <a href="https://www.autodesk.com/products/fusion-360/overview?term=1-YEAR&amp;tab=subscription">Fusion 360</a> のような大掛かりな CAD ソフトを使うほうがいいと思うけど、木工に関しては caDIY3D が良さそうだ。</p>
        <p>とりあえず 30 日トライアルをやっている。</p>
        <p><img src="https://www.kbaba1001.com/img/posts/202409280830/caDIY3D-2.png" alt="caDIY3D-2"></p>
        <p>30分くらい使っただけで簡単な棚を設計できた。</p>
        <p><img src="https://www.kbaba1001.com/img/posts/202409280830/caDIY3D-3.png" alt="caDIY3D-3"></p>
        <p>木取り図も自動生成できて最高。毎回これを頭で考えるのが若干大変だった。</p>
        <p><img src="https://www.kbaba1001.com/img/posts/202409280830/caDIY3D-4.png" alt="caDIY3D-4"></p>
        <p>木取り図から値段も計算してくれる。便利じゃん！</p>
        ]]>
      </content:encoded>
      <pubDate>Sat, 28 Sep 2024 08:30:16 GMT</pubDate>
    </item>
    <item>
      <title>紙に書いた今年の日記が500ページくらいあってキモい</title>
      <link>https://www.kbaba1001.com/posts/202409280809_paper-diary/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202409280809_paper-diary/</guid>
      <content:encoded>
        <![CDATA[<p>皆さんは日記帳を持ってますか？</p>
        <p>私の日記帳はこんな感じです。</p>
        <p><img src="https://www.kbaba1001.com/img/posts/202409280809/diary2.jpg" alt="日記2"></p>
        <p><a href="https://www.kokuyo-st.co.jp/stationery/campus-notebinder/">コクヨ ノートのように使えるバインダー</a> に
        <a href="https://www.kokuyo-st.co.jp/stationery/looseleaf/b5.html">しっかり書けるA罫7mmドット入りルーズリーフ</a> を入れて、
        <a href="https://www.pentel.co.jp/products/ballpointpen/energel/">エナージェル</a>ボールペンやガラスペンで日記を書くのが好きだ。</p>
        <p>SNS をやめてから日記を1日２，３回くらい書くようになった。
        ネットに書けないことも紙には書けるし、炎上しないから気が楽だ。</p>
        <p>特に読み返すわけでもないのだが、書いた分は別の厚めのルーズリーフケースに移し替えている。</p>
        <p>で、その結果、今年の日記がこんな感じ。</p>
        <p><img src="https://www.kbaba1001.com/img/posts/202409280809/diary1.jpg" alt="日記1"></p>
        <p>分厚くてキモい。。。</p>
        <p>しかもだいたいどのページもぎっちり書いてある。</p>
        <p>読み返してみると、なんか常に色々やっててこの人忙しそうだなと思った。</p>
        <p>別に普通のことなんだけど「今日は通院の日だ」みたいな記述もあって、少し狂気じみている。</p>
        <p>最近では日記を売る人もいると聞いたことある。
        守秘義務に関わることや個人名とか除けば自分の日記も売れそうではある。。。
        あんまそういう気持ちじゃないけど</p>
        ]]>
      </content:encoded>
      <pubDate>Sat, 28 Sep 2024 08:09:11 GMT</pubDate>
    </item>
    <item>
      <title>AIコンピュータについて</title>
      <link>https://www.kbaba1001.com/posts/202409280755_ai-computer/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202409280755_ai-computer/</guid>
      <content:encoded>
        <![CDATA[<p><img src="https://www.contec.com/-/media/Contec/jp/news/2024/24091000/img_01.jpg" alt="DX-M2300"></p>
        <p><a href="https://www.contec.com/jp/news/2024/2024091000/">DX-M2300</a> という組み込み用のパソコンがあるらしい。
        組み込み用というのはようするに Raspberry Pi みたいなやつの超すごいやつということらしい。
        ロボットの制御なんかに使えるみたいなんだけど、 Jetson AGX Orin 64GB という CPU/GPU を搭載していて、
        VRAM 64GB ということなのでかなり処理性能が高い。</p>
        <p>最近のローカルLLM、例えば llama などでも 70B くらいのがあるわけだが、こういうのを動かす環境が結局
        H100 みたいな超高級(500万円くらい) なマシンしかないという状況は結構きつくて、
        DX-M2300 シリーズはオープン価格だがだいたい 40 万～ 100 万くらいのはずで、
        比較的手が出しやすい。</p>
        <p>むりにファンレスである必要はないと思うのだが（というかこのでかいヒートシンクつけるくらいならファンつけてくれたほうが。。。）、
        たぶんそこはロボットとして音を出したくないみたいな需要があるのだろう。
        たしかにドラえもんからファンの音がしていたら嫌だ。</p>
        <p>ただいまいちこのマシンの購入方法がわからない。
        代理店に問い合わせてくれとのことなのだが、１台だけの発注を受け入れているのかどうか。。。</p>
        <p>RTXシリーズがなかなか5000系がでなくて Nvidia がもう個人向けの GPU に興味なさそうな気がするので、
        Jetson シリーズにはちょっと期待している。</p>
        <p>とにかく VRAM が大きい GPU がそれなりの値段で欲しい。。。</p>
        ]]>
      </content:encoded>
      <pubDate>Sat, 28 Sep 2024 07:55:55 GMT</pubDate>
    </item>
    <item>
      <title>Web UIデザインの勉強をしている</title>
      <link>https://www.kbaba1001.com/posts/202409100908_learning-ui-design/</link>
      <guid isPermaLink="false">https://www.kbaba1001.com/posts/202409100908_learning-ui-design/</guid>
      <content:encoded>
        <![CDATA[<p><img src="https://www.kbaba1001.com/img/posts/202409100908/ui-design.jpg" alt="UI Design Books"></p>
        <p>前から持っていた本も含めて上記の本を読んでいる。</p>
        <p>色彩検定３級は前から持っているのだが、内容を忘れてしまったので復習している。
        ちょっと概念過ぎて応用までが遠い気もする。</p>
        <h3>なぜ勉強しているのか</h3>
        <p>《kbaba1001|/img/horse.jpg|デザインのできるエンジニアになりたい》</p>
        <p>以前から画面を作る機会は多く、デザイナーを雇う予算がない開発の現場も多いので、
        私が自分でワイヤーフレームなど書くことも多々あり、デザインを勉強したいという気持ちは以前からあった。
        というか、以前からデザインは勉強しているのだが、いまいち正解がわからず自らをデザイナーと名乗るほど
        習得できている気がしない。</p>
        <p>ある意味で、デザインは機能を作ることより独学が難しいかもしれない。
        機能は動いているかどうかという明白は指標があるけど、デザインにはそれがない。
        素人でも口を出せる部分もある一方で、専門家らしい意見が求められる場合も多いように思う。
        結局のところ、なぜそのデザインにしたのかを自分なりに一つ一つ正解を作っていく分野という気がする。</p>
        <p>一方で、単に「デザイン」という場合、出版物（チラシとか本とか）のデザインを指す場合が多いように思う。
        私にとってそういうデザインも同人誌づくりでは必要なのだが、本職であるWebシステム開発で活かすのであれば、
        やはりWebデザインについて学びたい。
        印刷物は後から動いたり画面の大きさが変わったりしないので、どうしてもWebやスマホに応用が不十分なことがあるので、
        今回は Web UI デザインに焦点を絞っている本を買ってみた（下の２冊）。</p>
        <h3>感想『縁の下のUIデザイン』</h3>
        <p>かつてWeb+DB Press で連載していたものが本になったらしい。
        Web+DB Press は廃刊になってしまったのが未だに惜しい。。。</p>
        <p>内容としては UI の小技集だがどういう意図でそのUIを使えばいいかを
        比較しながら説明してくれているのでわかりやすかった。</p>
        <p>またどのようなUIが楽しいか、という観点でもUIを考えており、
        単に利便性の話だけでなくユーザーにとって楽しいと思えるシステムを
        提供できているかというのは指標として今後も大切にしたいと思った。</p>
        <p>私のような非デザイナーにはありがたい。</p>
        <p>エンジニアがデザインを学ぶ場合、ほとんどのデザイナーよりも実装力は高い場合が多いのではなかろうか。
        どのように HTML や CSS, JS を使えばその機能を実装できるかはエンジニアの方が詳しいはずだ。
        しかし、なぜその UI にするのかという部分でエンジニアはデザイナーに劣る。</p>
        <h3>感想『UIデザイン必携』</h3>
        <p>『縁の下のUIデザイン』と色彩検定３級の中間くらいの知識をちょうど補ってくれる感じで良かった。</p>
        <p>色彩検定３級で出てくる用語、概念を、じゃあWebデザインでどのように考えるかという部分が
        イマイチ自分の中で整理できていなかったのだが、この本はそのへんをうまく説明してくれている気がする。</p>
        <p>『縁の下のUIデザイン』ほど実装に特化しておらず、でもWebやスマホを中心としたUIの話が
        まとまっており良い感じだ。</p>
        <p>この本１冊での満足感はそこまで高くないかもしれないけど、最初の写真にある４冊全て含めると
        デザインについての学習はかなりできると思う。</p>
        ]]>
      </content:encoded>
      <pubDate>Tue, 10 Sep 2024 09:08:37 GMT</pubDate>
    </item>
  </channel>
</rss>